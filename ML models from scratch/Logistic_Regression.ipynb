{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOC9SKFT/oiOAvj7TYjMw3Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"2zC2dFE2V6ZS","executionInfo":{"status":"ok","timestamp":1694356447258,"user_tz":-360,"elapsed":358,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.datasets import make_classification"]},{"cell_type":"code","source":["class LogisticRegressionTest:\n","\n","  def __init__(self, learning_rate=0.01, iteration=100, activation=\"sigmoid\"):\n","    self.lr = learning_rate\n","    self.iter = iteration\n","    self.act = activation\n","    self.cost = 0\n","    #self.grad = 0\n","\n","  def fit(self, X, Y):\n","    self.m, self.n = X.shape\n","    self.x = X\n","    self.y = Y\n","    self.w = np.array([np.random.uniform(-1,1) for _ in range(self.n)], ndmin=1)\n","    self.b = np.random.uniform(-1,1)\n","\n","    for i in range(1, self.iter+1):\n","      self.update_weights()\n","      if i%25==0:\n","        print(f\"Iteration: {i} || Cross_Entropy_Loss: {self.cost}\")\n","    print(f\"Weights: {self.w} \\n|| Bias: {self.b}\")\n","    return self\n","\n","  def update_weights(self):\n","    y_pred = self.predict(self.x)\n","\n","    self.cost, dw, db = self.loss_gradient(self.y, y_pred)\n","\n","    self.w -= self.lr * dw\n","    self.b -= self.lr * db\n","\n","    return self\n","\n","  def predict(self, X):\n","    a = np.dot(X, self.w) + self.b\n","    if self.act == \"sigmoid\":\n","      return self.sigmoid(a)\n","    elif self.act == \"tanh\":\n","      return self.tanh(a)\n","    elif self.act == \"relu\":\n","      return self.relu(a)\n","    else:\n","      return f\"Activation not defined\"\n","\n","  def loss_gradient(self, y_true, y_pred):\n","    J = np.sum((-y_true* np.log(y_pred) - (1-y_true) * np.log(1-y_pred)))/self.m\n","\n","    dJdw = np.dot(self.x.T, (y_pred - y_true))\n","    dJdb =  np.mean((y_pred - y_true))\n","\n","    return J, dJdw, dJdb\n","\n","  def sigmoid(self, a):\n","    h = 1/(1 + np.exp(-a))\n","    #dh = h*(1-h)\n","    return h\n","\n","  def tanh(self, a):\n","    h = (np.exp(2*a) - 1)/(np.exp(2*a) + 1)\n","    #dh = 1 - h ** 2\n","    return h\n","\n","  def relu(self, a):\n","    h= np.max(0,a)\n","    #dh = np.max(0,1)\n","    return h"],"metadata":{"id":"GLW96k70lV6i","executionInfo":{"status":"ok","timestamp":1694357023450,"user_tz":-360,"elapsed":361,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["x, y = make_classification(n_samples=1000, n_features=5, n_classes=2)\n","x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n","\n","def main():\n","\n","  model =LogisticRegressionTest(iteration=100)\n","  model.fit(x_train, y_train)\n","\n","  model_y_pred = model.predict(x_test)\n","  model_y_pred = np.where(model_y_pred>0.7,1,0)\n","\n","  for i in range(y_test.shape[0]):\n","    if i%10==0:\n","      print(f\"True: {y_test[i]} || Pred: {model_y_pred[i]}\")\n","\n","\n","if __name__ == '__main__':\n","  main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qu4UsI9W3S5w","executionInfo":{"status":"ok","timestamp":1694357213850,"user_tz":-360,"elapsed":362,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"a298b8ed-9b7e-4846-dc2b-d4ab94940f6d"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Iteration: 25 || Cross_Entropy_Loss: 0.26168627426756325\n","Iteration: 50 || Cross_Entropy_Loss: 0.2616798245578209\n","Iteration: 75 || Cross_Entropy_Loss: 0.2616736034341765\n","Iteration: 100 || Cross_Entropy_Loss: 0.2616676028984294\n","Weights: [ 0.47686084  1.32537734 -0.31168655 -0.49743144  1.46490933] \n","|| Bias: 0.3505070478232643\n","True: 1 || Pred: 1\n","True: 0 || Pred: 0\n","True: 0 || Pred: 0\n","True: 1 || Pred: 1\n","True: 1 || Pred: 1\n","True: 1 || Pred: 0\n","True: 1 || Pred: 1\n","True: 1 || Pred: 1\n","True: 1 || Pred: 0\n","True: 1 || Pred: 1\n","True: 0 || Pred: 1\n","True: 0 || Pred: 0\n","True: 1 || Pred: 1\n","True: 0 || Pred: 0\n","True: 0 || Pred: 0\n","True: 0 || Pred: 0\n","True: 1 || Pred: 1\n","True: 1 || Pred: 1\n","True: 1 || Pred: 1\n","True: 0 || Pred: 0\n"]}]},{"cell_type":"code","source":["model2 = LogisticRegression()\n","model2.fit(x_train, y_train)\n","\n","pred = model2.predict(x_test)\n","\n","for i in range(y_test.shape[0]):\n","    if i%10==0:\n","      print(f\"True: {y_test[i]} || Pred: {pred[i]}\")\n","\n"],"metadata":{"id":"nbhBVYlwUaZI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694357226057,"user_tz":-360,"elapsed":348,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"50154319-c4f7-43c1-afd5-c5a8ed745af8"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["True: 1 || Pred: 1\n","True: 0 || Pred: 1\n","True: 0 || Pred: 0\n","True: 1 || Pred: 1\n","True: 1 || Pred: 1\n","True: 1 || Pred: 1\n","True: 1 || Pred: 1\n","True: 1 || Pred: 1\n","True: 1 || Pred: 0\n","True: 1 || Pred: 1\n","True: 0 || Pred: 1\n","True: 0 || Pred: 0\n","True: 1 || Pred: 1\n","True: 0 || Pred: 0\n","True: 0 || Pred: 0\n","True: 0 || Pred: 0\n","True: 1 || Pred: 1\n","True: 1 || Pred: 1\n","True: 1 || Pred: 1\n","True: 0 || Pred: 0\n"]}]}]}