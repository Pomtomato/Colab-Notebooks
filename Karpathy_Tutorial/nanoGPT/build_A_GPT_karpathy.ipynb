{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1jknh3oVeYJGq_p3t1rg5qOsE6R-DXMv-","authorship_tag":"ABX9TyMAS52aKUoGrgvtyFVR9SCP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"zhaViTOCvFaT","executionInfo":{"status":"ok","timestamp":1699068605677,"user_tz":-360,"elapsed":1447,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"outputs":[],"source":["with open('/content/drive/MyDrive/input.txt', 'r', encoding='utf-8') as f:\n","  text = f.read()"]},{"cell_type":"code","source":["print(\"length of dataset in characters: \", len(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTv_Pg4VqAh-","executionInfo":{"status":"ok","timestamp":1699068605678,"user_tz":-360,"elapsed":18,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"10d79bd9-8e6d-4de4-e65f-c7c2813d3709"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["length of dataset in characters:  1115394\n"]}]},{"cell_type":"code","source":["print(text[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WI-8R95jqHfu","executionInfo":{"status":"ok","timestamp":1699068605678,"user_tz":-360,"elapsed":17,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"e2146008-a18a-41c9-c157-61095aedb595"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n","Is't a verdict?\n","\n","All:\n","No more talking on't; let it be done: away, away!\n","\n","Second Citizen:\n","One word, good citizens.\n","\n","First Citizen:\n","We are accounted poor citizens, the patricians good.\n","What authority surfeits on would relieve us: if they\n","would yield us but the superfluity, while it were\n","wholesome, we might guess they relieved us humanely;\n","but they think we are too dear: the leanness that\n","afflicts us, the object of our misery, is as an\n","inventory to particularise their abundance; our\n","sufferance is a gain to them Let us revenge this with\n","our pikes, ere we become rakes: for the gods know I\n","speak this in hunger for bread, not in thirst for revenge.\n","\n","\n"]}]},{"cell_type":"code","source":["len(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F929I7UCfVSW","executionInfo":{"status":"ok","timestamp":1699068605678,"user_tz":-360,"elapsed":15,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"c74492a5-8a56-4a99-8fa3-591a1e69a593"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1115394"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(''.join(chars))\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bIZdn4LfqRTW","executionInfo":{"status":"ok","timestamp":1699068605678,"user_tz":-360,"elapsed":12,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"aa64b6f7-e2ac-4f18-9605-2886039419f0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","65\n"]}]},{"cell_type":"code","source":["# simplest for of tokenizer (character level)\n","s2i = {ch:i for i, ch in enumerate(chars)}\n","i2s = {i:ch for i, ch in enumerate(chars)}\n","encode = lambda s: [s2i[c] for c in s]\n","decode = lambda l: ''.join([i2s[i] for i in l])\n","\n","print(encode(\"hii there\"))\n","print(decode(encode(\"hii there\")))\n","# look up better tokenizers like the ones ChatGPT, google uses"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ntdyaFaEqh6X","executionInfo":{"status":"ok","timestamp":1699068605679,"user_tz":-360,"elapsed":10,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"ba791f2b-5287-4ff2-c997-c8f8aff5d512"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[46, 47, 47, 1, 58, 46, 43, 56, 43]\n","hii there\n"]}]},{"cell_type":"code","source":["import torch"],"metadata":{"id":"tNbs5AOcxZd8","executionInfo":{"status":"ok","timestamp":1699068609179,"user_tz":-360,"elapsed":3507,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["data = torch.tensor(encode(text), dtype=torch.long)\n","print(data.shape, data.dtype)\n","print(data[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M68rL2UBxDrk","executionInfo":{"status":"ok","timestamp":1699068610395,"user_tz":-360,"elapsed":1229,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"c4e3db10-dbd1-4e76-e5c9-b511d652ccce"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1115394]) torch.int64\n","tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n","         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n","        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n","        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n","         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n","         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n","        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n","        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n","         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n","        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n","        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n","        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n","        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n","        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n","        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n","         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n","         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n","         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n","        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n","        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n","        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n","        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n","        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n","        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n","         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n","         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n","        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n","        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n","        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n","         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n","        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n","        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n","         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n","        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n","        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n","        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n","        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n","        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n","        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n","        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n","        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n","        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n","         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n","        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n","        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n","        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n","        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n","        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n","        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"]}]},{"cell_type":"code","source":["n = int(0.9*len(data))\n","train_data = data[:n]\n","val_data = data[n:]"],"metadata":{"id":"E57CppixxXPl","executionInfo":{"status":"ok","timestamp":1699068610395,"user_tz":-360,"elapsed":58,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_data.shape, val_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jHD_Le5IxrYc","executionInfo":{"status":"ok","timestamp":1699068610396,"user_tz":-360,"elapsed":57,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"ee87ede6-a176-457e-80df-500e366b7b16"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1003854]), torch.Size([111540]))"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["block_size = 8\n","train_data[:block_size+1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fSVyrtigxvmz","executionInfo":{"status":"ok","timestamp":1699068610396,"user_tz":-360,"elapsed":49,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"c649dfab-7d47-4245-a3da-1b8890cfe673"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["'''\n","we can not feed into the transformer entire dataset which is computationally expensive and impractical.\n","We feed in random little chunks (block_size) to predict the label.\n","Also this breaking the entire dataset into block_size helps the transformer to see all the possible sequence of characters and its label.\n","e.g. the output below. This way when we sample from the trained transformer, even when we give 1 input, it can generate a output; since it has seen that kind of input and output mapping\n","\n","NOTE: the transformer can only take inputs from length 1->block_size. Any input greater than block_size needs to truncated and re-fed as another input\n","'''\n","x = train_data[:block_size]\n","y = train_data[1:block_size+1]\n","for t in range(block_size):\n","  context = x[:t+1]\n","  label = y[t]\n","  print(f\"when input is {context} the target is: {label}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"da7KB5VwyCaE","executionInfo":{"status":"ok","timestamp":1699068610396,"user_tz":-360,"elapsed":39,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"9bfde169-166e-432e-da39-d3057f2cf27a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["when input is tensor([18]) the target is: 47\n","when input is tensor([18, 47]) the target is: 56\n","when input is tensor([18, 47, 56]) the target is: 57\n","when input is tensor([18, 47, 56, 57]) the target is: 58\n","when input is tensor([18, 47, 56, 57, 58]) the target is: 1\n","when input is tensor([18, 47, 56, 57, 58,  1]) the target is: 15\n","when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is: 47\n","when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is: 58\n"]}]},{"cell_type":"code","source":["[i for i in range(8)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7enHaxahgfc-","executionInfo":{"status":"ok","timestamp":1699068610397,"user_tz":-360,"elapsed":36,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"7c42bc4a-93f7-4f11-c8b1-c3248073140a"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 2, 3, 4, 5, 6, 7]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["torch.manual_seed(1337)\n","batch_size = 4 # how many independent sequences will we process in parallel?\n","block_size = 8 # what is the maximum context length for predictions?\n","\n","def get_batch(split):\n","  # generate a small batch of data of inputs x and targets y\n","  data = train_data if split == 'train' else val_data\n","  ix = torch.randint(len(data) - block_size, (batch_size,))\n","  x = torch.stack([data[i:i+block_size] for i in ix])\n","  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","  return x, y\n","\n","xb, yb = get_batch('train')\n","print('inputs:')\n","print(xb.shape)\n","print(xb)\n","print('targets:')\n","print(yb.shape)\n","print(yb)\n","print('---------------')\n","\n","for b in range(batch_size): # batch dimension\n","  for t in range(block_size): # time dimension\n","    context = xb[b, :t+1]\n","    target  = yb[b, t]\n","    print(f\"when input is {context.tolist()} the target is: {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCgvJOnMy4Vm","executionInfo":{"status":"ok","timestamp":1699068610398,"user_tz":-360,"elapsed":31,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"290e5fa5-ea52-47b6-e963-4a5cf2ee1edd"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs:\n","torch.Size([4, 8])\n","tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n","        [44, 53, 56,  1, 58, 46, 39, 58],\n","        [52, 58,  1, 58, 46, 39, 58,  1],\n","        [25, 17, 27, 10,  0, 21,  1, 54]])\n","targets:\n","torch.Size([4, 8])\n","tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n","        [53, 56,  1, 58, 46, 39, 58,  1],\n","        [58,  1, 58, 46, 39, 58,  1, 46],\n","        [17, 27, 10,  0, 21,  1, 54, 39]])\n","---------------\n","when input is [24] the target is: 43\n","when input is [24, 43] the target is: 58\n","when input is [24, 43, 58] the target is: 5\n","when input is [24, 43, 58, 5] the target is: 57\n","when input is [24, 43, 58, 5, 57] the target is: 1\n","when input is [24, 43, 58, 5, 57, 1] the target is: 46\n","when input is [24, 43, 58, 5, 57, 1, 46] the target is: 43\n","when input is [24, 43, 58, 5, 57, 1, 46, 43] the target is: 39\n","when input is [44] the target is: 53\n","when input is [44, 53] the target is: 56\n","when input is [44, 53, 56] the target is: 1\n","when input is [44, 53, 56, 1] the target is: 58\n","when input is [44, 53, 56, 1, 58] the target is: 46\n","when input is [44, 53, 56, 1, 58, 46] the target is: 39\n","when input is [44, 53, 56, 1, 58, 46, 39] the target is: 58\n","when input is [44, 53, 56, 1, 58, 46, 39, 58] the target is: 1\n","when input is [52] the target is: 58\n","when input is [52, 58] the target is: 1\n","when input is [52, 58, 1] the target is: 58\n","when input is [52, 58, 1, 58] the target is: 46\n","when input is [52, 58, 1, 58, 46] the target is: 39\n","when input is [52, 58, 1, 58, 46, 39] the target is: 58\n","when input is [52, 58, 1, 58, 46, 39, 58] the target is: 1\n","when input is [52, 58, 1, 58, 46, 39, 58, 1] the target is: 46\n","when input is [25] the target is: 17\n","when input is [25, 17] the target is: 27\n","when input is [25, 17, 27] the target is: 10\n","when input is [25, 17, 27, 10] the target is: 0\n","when input is [25, 17, 27, 10, 0] the target is: 21\n","when input is [25, 17, 27, 10, 0, 21] the target is: 1\n","when input is [25, 17, 27, 10, 0, 21, 1] the target is: 54\n","when input is [25, 17, 27, 10, 0, 21, 1, 54] the target is: 39\n"]}]},{"cell_type":"code","source":["ix = torch.randint(len(train_data) - 8, (4,))\n","[data[i:i+block_size] for i in ix]\n","torch.stack([data[i:i+block_size] for i in ix])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hbo6g95G3gNY","executionInfo":{"status":"ok","timestamp":1699068610398,"user_tz":-360,"elapsed":26,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"d8c1e98f-c499-40d4-9d97-86954d048ade"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[57, 43, 60, 43, 52,  1, 63, 43],\n","        [60, 43, 42,  8,  0, 25, 63,  1],\n","        [56, 42,  5, 57,  1, 57, 39, 49],\n","        [43, 57, 58, 63,  6,  1, 58, 46]])"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["torch.zeros((1,1), dtype=torch.long).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qZi0djqxf5S","executionInfo":{"status":"ok","timestamp":1699068610399,"user_tz":-360,"elapsed":24,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"5e4b410e-1d32-4512-ec5a-24c3cfbaa1c2"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 1])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# @title ######simplest implementation using Bigram representation and jank\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","torch.manual_seed(1337)\n","\n","\n","# this simplest implementation of the model is ridiculus; since it is only a bigram model,\n","# so to predict next character it only uses the immediete previous character. But we are feeding it all context before the label,\n","# which are not being used. this is because current implementaion is written in a general way.\n","# we fed in increasing sizes of context, but then only looked at the very last character and used it to predict next character\n","\n","\n","# other words the token are not communicating with each other\n","class BigramLanguageModel(nn.Module):\n","\n","  def __init__(self, vocab_size):\n","    super().__init__()\n","    # each token directly reads off the logits for the next token from a lookup table\n","    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n","\n","  def forward(self, idx, targets=None):\n","\n","    # idx and targets are both (B,T) tensor of integers\n","    logits = self.token_embedding_table(idx) # (B, T, C) batch, time, channel\n","    # this nn.Embedding has done all the intermediete work, that was done explicitly for 'makemore' model\n","    if targets is None:\n","      loss = None\n","    else:\n","      B, T, C = logits.shape # the way we implemented logits, it gives (batch, Time, channel)\n","      # but pytorch cross entropy expects (B, C, T), basically it expects 'C' in the dim=1\n","      logits = logits.view(B*T, C)\n","      targets = targets.view(B*T)\n","      loss = F.cross_entropy(logits, targets)\n","\n","    return logits, loss\n","\n","  def generate(self, idx, max_new_tokens):\n","    # idx is (B, T) array of indices in the current context\n","    for _ in range(max_new_tokens):\n","      # get the predictions\n","      # also when we run generate() it give only logits as (B,T,C) and loss=None\n","      logits, loss = self(idx) #self.forward(idx)\n","      #print(logits.shape)\n","\n","      # focus only one the last time step\n","      logits = logits[:,-1,:] # becomes (B, C) # we pluck out the last element in 'T' dim, which are the labels of what comes next\n","      #print(logits.shape)\n","\n","      # apply softmax to get probabilities\n","      probs = F.softmax(logits, dim=1) # (B, C) # softmaxing accross 'T' dim\n","      #print(probs.shape)\n","\n","      # sample from the distribution\n","      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","\n","      # append sampled index to the running sequence\n","      idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","      #print(idx.shape)\n","    return idx\n","\n","\n","m = BigramLanguageModel(vocab_size)\n","logits, loss = m(xb, yb) # xb->torch.Size([4, 8]), yb->torch.Size([4, 8])\n","print(logits.shape, loss.item()) # (B*T, C)-> torch.Size([4*8, 65])\n","\n","\n","# now since we know there are '65' characters/tokens, at initialization we know what the loss should be\n","# at init all '65' char should have equal probability, So neg log likelihood-> -ln(1/65)=4.1743872699\n","# loss.item() -> 4.878634929656982 ||| as we can see the loss we got is not exactly the same, and thus the model has some jitter/entropy and didn't learn correctly\n","\n","\n","# idx = torch.zeros((1,1), dtype=torch.long) -> feed in [0] to kick of generation, remember '0' was the element for 'new_line' character\n","# run idx through m.generate for 100 max_tokens, and then index into the 'B' dimension[0] to pluck out the elements from each batch 'B'\n","print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iw35A2vY3kFf","executionInfo":{"status":"ok","timestamp":1699068610399,"user_tz":-360,"elapsed":18,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"db1c91e6-82a2-4827-a9c6-065a49496775"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 65]) 4.878634929656982\n","\n","Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"]}]},{"cell_type":"code","source":["# create a Pytorch optimizer\n","optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3) # SGD->stochastic gradient descent (previously used)"],"metadata":{"id":"G9g3jF6FBPS-","executionInfo":{"status":"ok","timestamp":1699068611000,"user_tz":-360,"elapsed":616,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","for steps in range(10000):\n","\n","  # sample a batch of data\n","  xb, yb = get_batch('train')\n","\n","  # evaluate the loss\n","  logits, loss = m(xb, yb)\n","  optimizer.zero_grad(set_to_none=True) # setting parameters previous gradients to None\n","  loss.backward()  # getting gradients\n","  optimizer.step() # using gradients to update parameters\n","\n","# here we are only optimizing(by backprop) the embedding table (which was initialized randn) since we didn't add any other layer\n","print(loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CSvj-Paw66G4","executionInfo":{"status":"ok","timestamp":1699068635881,"user_tz":-360,"elapsed":24885,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"575bc5d5-9fcd-457a-c0d7-7be9e44b7a8d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["2.5727508068084717\n"]}]},{"cell_type":"code","source":["print(decode(m.generate(torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S08F0u878ZKC","executionInfo":{"status":"ok","timestamp":1699068635881,"user_tz":-360,"elapsed":24,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"b7bce94a-d640-4c39-99c2-b681092256b1"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Iyoteng h hasbe pave pirance\n","Rie hicomyonthar's\n","Plinseard ith henoure wounonthioneir thondy, y heltieiengerofo'dsssit ey\n","KIN d pe wither vouprrouthercc.\n","hathe; d!\n","My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so it t jod weancotha:\n","h hay.JUCle n prids, r loncave w hollular s O:\n","HIs; ht anjx?\n","\n","DUThinqunt.\n","\n","LaZAnde.\n","athave l.\n","KEONH:\n","ARThanco be y,-hedarwnoddy scace, tridesar, wnl'shenous s ls, theresseys\n","PlorseelapinghiybHen yof GLUCEN t l-t E:\n","I hisgothers je are!-e!\n","QLYotouciullle'z\n"]}]},{"cell_type":"markdown","source":["# The mathematical trick in self-attention"],"metadata":{"id":"Mfj8cl3zw5Ny"}},{"cell_type":"code","source":["# the simplest implementation didn't have tokens communicating with each other. But we want the tokens to communicate,\n","# and communicate in a specific way. Specifically, token=4 should not communicate with token=5,6,7 since these are the future token.\n","# rather token=4 should communicate with all previous tokens=3,2,1,0.\n","\n","\n","# consider the following toy example\n","torch.manual_seed(1337)\n","B,T,C = 4,8,2\n","x = torch.randn(B,T,C) # batch, time, channels\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OolFfjfvnv2u","executionInfo":{"status":"ok","timestamp":1699068635881,"user_tz":-360,"elapsed":22,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"5fd4b40e-03ad-47d3-eb83-c8abc079dc59"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 2])"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["# @title #####version1 -- average\n","#very weak interaction system. Averaging current and all previous tokens (T dim) through the channel dim for all batch dim.\n","\n","# xbow->bag of words; we want x[b,t] = mean_{i<=t} x [b,i]\n","xbow = torch.zeros((B,T,C))\n","for b in range(B):\n","  for t in range(T):\n","    xprev = x[b,:t+1] # (t,C)\n","    xbow[b,t] = torch.mean(xprev, dim=0)"],"metadata":{"id":"Fx8hL9nAo8oy","executionInfo":{"status":"ok","timestamp":1699068635882,"user_tz":-360,"elapsed":19,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["x, xprev, torch.mean(xprev, dim=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTk3xYVyJC-E","executionInfo":{"status":"ok","timestamp":1699068635883,"user_tz":-360,"elapsed":19,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"0b4fc618-c7ae-401d-ade2-be14f09b95c8"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[[ 0.1808, -0.0700],\n","          [-0.3596, -0.9152],\n","          [ 0.6258,  0.0255],\n","          [ 0.9545,  0.0643],\n","          [ 0.3612,  1.1679],\n","          [-1.3499, -0.5102],\n","          [ 0.2360, -0.2398],\n","          [-0.9211,  1.5433]],\n"," \n","         [[ 1.3488, -0.1396],\n","          [ 0.2858,  0.9651],\n","          [-2.0371,  0.4931],\n","          [ 1.4870,  0.5910],\n","          [ 0.1260, -1.5627],\n","          [-1.1601, -0.3348],\n","          [ 0.4478, -0.8016],\n","          [ 1.5236,  2.5086]],\n"," \n","         [[-0.6631, -0.2513],\n","          [ 1.0101,  0.1215],\n","          [ 0.1584,  1.1340],\n","          [-1.1539, -0.2984],\n","          [-0.5075, -0.9239],\n","          [ 0.5467, -1.4948],\n","          [-1.2057,  0.5718],\n","          [-0.5974, -0.6937]],\n"," \n","         [[ 1.6455, -0.8030],\n","          [ 1.3514, -0.2759],\n","          [-1.5108,  2.1048],\n","          [ 2.7630, -1.7465],\n","          [ 1.4516, -1.5103],\n","          [ 0.8212, -0.2115],\n","          [ 0.7789,  1.5333],\n","          [ 1.6097, -0.4032]]]),\n"," tensor([[ 1.6455, -0.8030],\n","         [ 1.3514, -0.2759],\n","         [-1.5108,  2.1048],\n","         [ 2.7630, -1.7465],\n","         [ 1.4516, -1.5103],\n","         [ 0.8212, -0.2115],\n","         [ 0.7789,  1.5333],\n","         [ 1.6097, -0.4032]]),\n"," tensor([ 1.1138, -0.1641]))"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["x[0], xbow[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eSonM9RCrIvI","executionInfo":{"status":"ok","timestamp":1699068635883,"user_tz":-360,"elapsed":17,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"48695e48-1cb5-4d56-9b84-97cea3830bdf"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0.1808, -0.0700],\n","         [-0.3596, -0.9152],\n","         [ 0.6258,  0.0255],\n","         [ 0.9545,  0.0643],\n","         [ 0.3612,  1.1679],\n","         [-1.3499, -0.5102],\n","         [ 0.2360, -0.2398],\n","         [-0.9211,  1.5433]]),\n"," tensor([[ 0.1808, -0.0700],\n","         [-0.0894, -0.4926],\n","         [ 0.1490, -0.3199],\n","         [ 0.3504, -0.2238],\n","         [ 0.3525,  0.0545],\n","         [ 0.0688, -0.0396],\n","         [ 0.0927, -0.0682],\n","         [-0.0341,  0.1332]]))"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# @title #####version 2 -- matrix multiplication system\n","wei = torch.tril(torch.ones(T,T))\n","wei = wei / wei.sum(1, keepdim=True)\n","print(wei)\n","xbow2 = wei @ x # (T,T) @ (B,T,C) ---broadcast--> (B,T,T) @ (B,T,C) ---> (B,T,C)  '@ here is batched matrix multiplication'\n","print(xbow[0],'\\n', xbow2[0])\n","torch.allclose(xbow, xbow2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mAY2EK6JuOi6","executionInfo":{"status":"ok","timestamp":1699068635883,"user_tz":-360,"elapsed":14,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"8408b20d-ddf7-4ce0-ee75-ab044f808f60"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n","        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n","        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n","        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n","tensor([[ 0.1808, -0.0700],\n","        [-0.0894, -0.4926],\n","        [ 0.1490, -0.3199],\n","        [ 0.3504, -0.2238],\n","        [ 0.3525,  0.0545],\n","        [ 0.0688, -0.0396],\n","        [ 0.0927, -0.0682],\n","        [-0.0341,  0.1332]]) \n"," tensor([[ 0.1808, -0.0700],\n","        [-0.0894, -0.4926],\n","        [ 0.1490, -0.3199],\n","        [ 0.3504, -0.2238],\n","        [ 0.3525,  0.0545],\n","        [ 0.0688, -0.0396],\n","        [ 0.0927, -0.0682],\n","        [-0.0341,  0.1332]])\n"]},{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["torch.manual_seed(42)\n","#a = torch.ones(3,3)\n","a = torch.tril(torch.ones(3,3)) # make a upper triangular tensor\n","a = a / torch.sum(a, 1, keepdim=True) # normalizing through dim=1 or accross row of 'a'\n","# now if we see the tensor->'a' ; we will understand that (a @ b) will essentially average the 'b' column values by using 'a'\n","b = torch.randint(0,10,(3,2)).float()\n","c = a @ b\n","print('a=','\\n',a)\n","print('b=','\\n',b)\n","print('c=','\\n',c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_d-fF_nFrMJf","executionInfo":{"status":"ok","timestamp":1699068636794,"user_tz":-360,"elapsed":921,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"336eecb2-086f-4d86-e3fb-b7fb3a08a112"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["a= \n"," tensor([[1.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000],\n","        [0.3333, 0.3333, 0.3333]])\n","b= \n"," tensor([[2., 7.],\n","        [6., 4.],\n","        [6., 5.]])\n","c= \n"," tensor([[2.0000, 7.0000],\n","        [4.0000, 5.5000],\n","        [4.6667, 5.3333]])\n"]}]},{"cell_type":"code","source":["# @title #####version 3: use softmax\n","tril = torch.tril(torch.ones(T,T))\n","wei = torch.zeros((T,T)) # think of it as interaction strength which tells us how much of the token from the past we want to aggregate\n","# these weights are not going to be zero forever. The token weight/ wei will look at each other, find affinity to other tokens, and change its(wei) values\n","wei = wei.masked_fill(tril == 0, float('-inf')) # tells us which tokens can interact with each other, and which can not; future can not communicate with past\n","wei = F.softmax(wei, dim=1)\n","xbow3 = wei @ x # (T,T) @ (B,T,C) --> (B,T,T) @ (B,T,C) --> (B,T,C)\n","torch.allclose(xbow, xbow3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1BUCDZmer6bw","executionInfo":{"status":"ok","timestamp":1699068636794,"user_tz":-360,"elapsed":57,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"d712463e-f7e0-43cd-8b4d-eabe23430891"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["tril"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCDfIN7UyDcJ","executionInfo":{"status":"ok","timestamp":1699068636794,"user_tz":-360,"elapsed":53,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"fe51d34d-3d20-4880-ec6f-4856ab587a88"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 1., 0., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 1., 0., 0., 0.],\n","        [1., 1., 1., 1., 1., 1., 0., 0.],\n","        [1., 1., 1., 1., 1., 1., 1., 0.],\n","        [1., 1., 1., 1., 1., 1., 1., 1.]])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["wei = torch.zeros((T,T))\n","wei = wei.masked_fill(tril == 0, float('-inf'))\n","print(wei)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r4zc-JqayFiw","executionInfo":{"status":"ok","timestamp":1699068636794,"user_tz":-360,"elapsed":50,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"990f6545-2d16-4ad8-a119-3d8ab12477ba"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0.]])\n"]}]},{"cell_type":"code","source":["wei = F.softmax(wei, dim=-1)\n","# softmax-> exp()/sum(exp()) -> and exp(0)=1 and exp(-inf)=0\n","# thus softmax basically works as normalizer here\n","wei, wei.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sy9pbzu5yGoF","executionInfo":{"status":"ok","timestamp":1699068636795,"user_tz":-360,"elapsed":48,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"7e45f8f2-6f54-409c-fc56-e2dcb8499963"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n","         [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n","         [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n","         [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]]),\n"," torch.Size([8, 8]))"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["x.shape ,x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNTLvNkDNmrS","executionInfo":{"status":"ok","timestamp":1699068636795,"user_tz":-360,"elapsed":46,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"50cc526f-dff7-49df-f529-08a7b675be5f"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([4, 8, 2]),\n"," tensor([[[ 0.1808, -0.0700],\n","          [-0.3596, -0.9152],\n","          [ 0.6258,  0.0255],\n","          [ 0.9545,  0.0643],\n","          [ 0.3612,  1.1679],\n","          [-1.3499, -0.5102],\n","          [ 0.2360, -0.2398],\n","          [-0.9211,  1.5433]],\n"," \n","         [[ 1.3488, -0.1396],\n","          [ 0.2858,  0.9651],\n","          [-2.0371,  0.4931],\n","          [ 1.4870,  0.5910],\n","          [ 0.1260, -1.5627],\n","          [-1.1601, -0.3348],\n","          [ 0.4478, -0.8016],\n","          [ 1.5236,  2.5086]],\n"," \n","         [[-0.6631, -0.2513],\n","          [ 1.0101,  0.1215],\n","          [ 0.1584,  1.1340],\n","          [-1.1539, -0.2984],\n","          [-0.5075, -0.9239],\n","          [ 0.5467, -1.4948],\n","          [-1.2057,  0.5718],\n","          [-0.5974, -0.6937]],\n"," \n","         [[ 1.6455, -0.8030],\n","          [ 1.3514, -0.2759],\n","          [-1.5108,  2.1048],\n","          [ 2.7630, -1.7465],\n","          [ 1.4516, -1.5103],\n","          [ 0.8212, -0.2115],\n","          [ 0.7789,  1.5333],\n","          [ 1.6097, -0.4032]]]))"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# @title #####version 4: self-attention\n","torch.manual_seed(1337)\n","B,T,C = 4,8,32\n","x = torch.randn(B,T,C)\n","\n","# let's see a single Head perform self-attention\n","head_size = 16\n","'''\n","# previously we initialized wei with all zeros(a uniform initialization). But some tokens might have strong affinities for specific tokens\n","# so this 'affinity' tensor wei should not be uniform, rather represent the affinities between tokens\n","# first we say every token emits a 2-d vector of keys and queries; key-> what do I contain, query-> what am I looking for\n","# the way we get affinities between tokens is, a dot product between the keys and queries\n","# so my tokens query dot products with all the other keys of previous tokens.\n","# now If my query and any of the keys are similarly arranged, it will give out a high value for the corresponding positions and becomes our wei(affinity representation tensor)\n","'''\n","key = nn.Linear(C, head_size, bias=False) # key-> what do I contain # (32,16)\n","query = nn.Linear(C, head_size, bias=False) # query-> what am I looking for # (32,16)\n","value = nn.Linear(C, head_size, bias=False)\n","k = key(x) #  indexing into (C,16) with [B,T,C] ---> (B,T,16)\n","q = query(x) #  indexing into (C,16) with [B,T,C] ---> (B,T,16)\n","wei = q @ k.transpose(-2,-1) # (B,T,16) @ (B,16,T) ----> (B,T,T)\n","# thus wei is not intiatized uniformly anymore but in a data dependent manner and preserves the affnity between tokens/nodes\n","\n","tril = torch.tril(torch.ones(T,T))\n","#wei = torch.zeros((T,T))\n","wei = wei.masked_fill(tril == 0, float('-inf')) # <---- THIS IS A TRANSFORMER DECODER BLOCK  # removing this makes it an encoder block\n","# !!THERE IS ALSO TRANSFORMER ENCODER BLOCK USED IN 'cross-attention'\n","wei = F.softmax(wei, dim=-1) # (B,T,T)\n","\n","v = value(x) # (C,16),[B,T,T]->(B,T,16)adding another linear layer which will output the values we will finally aggregate, instead of raw 'x'\n","'''for a single head-->\n","we can think of 'x' as private information to this token. so i'm a 5th token and i've this identity; this info is kept in vector 'x'\n","now 'x' will emit-> heres what i'm interested in(query), heres what i have(key), and if you find me interesting heres what i will communicate to you\n","and this all is stored in 'v'; then v gets aggregated with wei\n","'''\n","\n","out = wei @ v # this line does the actual average of present token wrt all past tokens\n","# and thus the weighted aggregation(out) is a function in a data-dependent manner between the keys and queries of the tokens/nodes\n","# (B,T,T) @ (B,T,16)->(B,T,16)\n","# if we don't use 'out = wei @ v', instead use 'out = wei @ x', we will have out=(B,T,32); this shouldn't? be a problem for single head\n","# but for multiple heads where we want to the information to flow indepenently and concatanate, this 'v' must be used\n","\n","# torch.Size([4, 8, 32]) previously without v = value(x)\n","out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wVttXeLhye3k","executionInfo":{"status":"ok","timestamp":1699068636795,"user_tz":-360,"elapsed":43,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"663519ed-e338-4ddf-b0b9-cc2ccdab1b49"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 16])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["k.shape,wei.shape,v.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5OcJS7bPlnR","executionInfo":{"status":"ok","timestamp":1699068636795,"user_tz":-360,"elapsed":39,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"113b4015-b50a-49c4-bf18-3de9f0e94530"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([4, 8, 16]), torch.Size([4, 8, 8]), torch.Size([4, 8, 16]))"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["tril"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E64CNcG4DeH3","executionInfo":{"status":"ok","timestamp":1699068636796,"user_tz":-360,"elapsed":38,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"e52e7e3f-34a7-4693-a7df-19aa7b19b58b"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 1., 0., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 1., 0., 0., 0.],\n","        [1., 1., 1., 1., 1., 1., 0., 0.],\n","        [1., 1., 1., 1., 1., 1., 1., 0.],\n","        [1., 1., 1., 1., 1., 1., 1., 1.]])"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["wei"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XX0s0b44Dey0","executionInfo":{"status":"ok","timestamp":1699068636796,"user_tz":-360,"elapsed":35,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"dc02e130-59d5-454b-bdea-cc34a90b9afd"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n","         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n","         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n","         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n","\n","        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n","         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n","         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n","         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n","\n","        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n","         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n","         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n","         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n","\n","        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n","         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n","         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n","         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n","         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n","       grad_fn=<SoftmaxBackward0>)"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# @title #####explanation how the key and queries find affinities\n","'''\n","# we see here the 8th token and 4th token have high values\n","# this 8th token knows what content(char) it has and knows its position(8th)\n","# and based on its knowledge of content and position, it makes a query\n","# e.g query (hey i'm a vowel at 8th position and i'm looking for specific kind of char upto 4th postion)\n","# and then all the tokens/nodes get to emit keys and maybe one of the channels emit i'm that specific char and i'm upto position 4\n","# and that key will have high value on that specific channel; that is how when ->query @ key-> they find each other and create a high affinity\n","# and when they have a high affinity(high value); the softmax will aggregate a lot the keys information into my position(query)\n","# thus I'll get to learn a lot about it\n","'''\n","print(wei[0])\n","wei[0][7]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oBJYY7iiSsbn","executionInfo":{"status":"ok","timestamp":1699068636796,"user_tz":-360,"elapsed":32,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"e6d15099-6bfd-43a3-b999-f9a86dd9a0d3"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n","        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n","        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n","        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n","       grad_fn=<SelectBackward0>)\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391],\n","       grad_fn=<SelectBackward0>)"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":[" out"],"metadata":{"id":"Nff-OV5MDfMo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notes:\n","- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights. This attention mechanism in principal can be used in any sort data represented by directed graph\n","- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n","- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other. Think of it as 4 seperate pools/batchs of 8, where the 8's only talk to each other in every pool.\n","- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n","- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n","- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"],"metadata":{"id":"h9P4CsurZ7e6"}},{"cell_type":"markdown","source":["![Untitled.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASwAAACoCAMAAABt9SM9AAAAhFBMVEX///+hoaHDw8OdnZ1NTU3AwMAAAACHh4f8/Pz5+fmLi4v39/f09PSGhoaPj4/u7u5aWlpvb2/o6Oh8fHze3t7Ly8vj4+NkZGTJycnW1ta2traUlJQyMjJeXl5zc3N+fn5FRUVSUlKurq6xsbFAQEAqKiohISE1NTUmJiYPDw8YGBgWFhbJMwHkAAAO9ElEQVR4nO1d53biOBh1xzbuBfeKgSTz/u+32JAguciWJQN7DvfH7FImmlxLV5++Job54IMPPvjggw8++OCDDz744APakE0vZnlW9MwnDKY5Yc3zte/snzAYdWh1brmsyImsbbnxxoNFRhYYMccd1SxIDhsPRh1K0rCPf7SXXOoNB4sqm1N+X2iiFXgbDkYfXHOE35B5wd9oLM0NHPidKNPljQbbAGo+lKlDsM3kiqyRNV5bz9BJKnD5sXe1nN1grMgaXXOh4Iy9/X5Qk4kPAvo67zQTcu4L/4ttUQymPpGFiPZg5aSWxzbtsTbAQVCmP7MoP+4EsbLVLTdgSig4xIfsqJqthmchPtSCtxd5Dzn7tUCjOZiOejDMcUo73waqCL2UewYPT1PjnaC34uHBNIHiWFtAzsC5rwWSZEF7uINaOLiIe4vak+ANRA0pDrYBIh14IV+qg5P9gI9frijY1r9L2Ya3Qv9Lgt/g3nwdHsEtSJSus0qToJWnUjj1mMFtBkGzWHaltEfWviIfa0tAXOhN+2cGSX7dOzSugvGTX+kybXDOHiQ27JHFlBTG2hDgmVYOOpp2kOEV0zjzaOfTOfe8Anxv7zB+n6w3V/gMMA1kK2//Y5QgWeFJIEfVpOlJqtTe4AOyKuonBqoADcFRskQqp+k0PTcstJm0GJCVWXSNYMoogGcpZx1Z8DKsaRxCaklgNcbJezvrgKxSTnKqVjBdQPqtl+2fsMAnFGwfrWK7CZz1iOiTJV81K37jpRgawAtRuv42igQuPJnGgc28/4y+h7RPVtTuAE65dQBgNbQA8CsoX5lp2hLoadBKioOxvSXdJ4vvjl5y7r6rkzkHZ71TSRLscappekv7h/YeWUp1f0zH6k0jGL4LvpJNEzrrKv2VQ4Yc1iPFhKYQ92eHjfrp3wE2SlDj/m5PBh/lD5KBo6NmJ2/pZY4mvcrXf7NFOYzgIvbWege+4t/TFWhMG4I57dVgppNm1KGC55LfID2Fr0IgTnzAV9QtxGjqR2qDUIYWvKPHJvoeZ4stgqbwKa+GYHx5mdWIK8iw3y6Y6Ai+PWIgaEbOxOfTWdBDivOL1+OxzIbIGhUzLnszc94UfEZWs/4z9K0rgYcmvR6BLXriwV+3w0joPxolGQ9Tt+GgLaLiq2HeEkAiwQUfYmjZXeQ4P52q6bAiNpLupM7wlxpYiyaLStnRc4rjE0L7S5bx3aoQfc+L/Div1PuT5v7lCT2ZVX+tNo3NMjaMroOFvBXUyNNNTD8svhKKAGiFFvF64RYqG/2JlHkRGZ0WW8buwYrixIYe2HoiOnMHQS+g4dkmx35WjvSrlu3osMUXfVp2y1x9ZkH3HLEOSjZrdHbKpRtzX1sAfnDUOaTTJioMtnq5DbGAqzv0vvccH4k7eMs9fS31IkevNueVbMpyH4J4bqnDleS1ZsnS47Jm7+a/tB3kxfOqBaHKg9r+C/d8Op0XByhklm6OChYUzD2GSOX5Ed/n4TvIVeu0/DTFbZYSPAcZO2GUQLeG2t6+GTJsyMQYwSPTek26m2zjj7uaLWOo7TfwuKq9C17gElzD1WqVH9H2O7DJYrjm+d75VVyt1K0xbb8Dn6zryfrJS1F21x7lV7DFT61BZhVZjOKq3a74rK2RwGjC1q1Rbf/7cJWlWXfmPI1DxQIUJEYAJluT2t5hHVmMdz3dK88JlhFxhTktVbTZvZIsZp8bzqX5fWWGRmBdkeki7RMkscMFQ7cQ2t5hLVnXk3WWnm+HNU8P1NAxNc00/cR2qfq+EnJvx27p3EJp++0La8ky2SZNLeUq83oARghk33bplXoi9XYpFurW/FhryeKl7/Mp/Rcy0WWgXH5DS8zuPnBSLGILre0dVs8sza/V6juohREDQrbpbJRDX+VKLFD5GW3vsF6zbkPY47EMldz7dlVFl1qgZFbl57S9AxlZoT1lmO6I4mdKe6KK+5UzJJhR+Vltv32LhCxzuvZVIYrNinybrEnwA4ZA6tZCbSQiy0X8ZY8kob4omTijnHuIYEstJj+CQEIWsnSRMZZuiV7sZq1Ba7PRfd0pzZnNqXuCJlV+t1RgScgqkG7TZdV4imjnbGS2Fu3h6Aa3lGr/J03r2WAmNiYK0RdpewcCskxoYnlFI9SQIucLVMsPVNA75rCd+2d3StN/p5HeDYRQx+bWMm2/fXU9WVDpYvRdxbwEJUWI84cyNesb+5phafvq6/ylhxt4ZEd0C8fuJSBLB2eOZV3nciiBP820Z6a3lo0FlqKyPiGLxkkwYGuptncgICsH7AZNapfP/geyrmZakGgTPSsOY0l1tNBT+Z2Ko4zryYJLF5V20AguKp3JSXenvNPeIFONIiCVX67tHdaT5QwP6cEFmks20vvATtvUHCJ7mxiAymNo++37FMnSJXj95CiyzBLxUPXlWQ34+NMtbJ8GyTLsvVFIvaRU5DLMUcK0v2xZOnRnC0vbO6wnS7GhNadV/cpFpMCbaJM12dS9352q8bS9A8Fu6ILkaOWlv+iUDGEpsSAbUSUIQgk6lA5zZgcZriqPqe0dCMiCfl/7K2IURQH/AYMSYwAKlIpffyc8D08m2kU4PRgZ9hpkiMjygD0rkr6Fsiwb0M5KECoNH5WKbPAF1F+mADZdEzQiIEsBGmoc6mPdAjTqLwjfHTzryqEl728awd3py10NAEi8DjHyF4pRzw7qkmKec0ES4K00WrNMlqLT9sURsgeInH8lYrvTxiIZf2DBVRZJZezbEmTQe5j2Ig7u2j7qg0CCiCwfsWehGsD1htX8ltf8C2TXoxMEG8NfHjI2W2QBi2KSkZn2gfXQjgoh+3+7mQXY7bg5NoShMHvCePRnyiRHOk/5EFn+VpnRO3BrwVR5MrL2waC8rEMszHg5HfCozDftt9lv0LQ6TrkkCKHDdjveSiQiSxNCeTcMHe6TidAr8DdBOyuSEpmJztD+Z2+Ti2n0myJjsUVCltMleovWEaJLEYMFmfU7cM2xUhlIUI69Ym2SVjhSY4ITOyex4O9J8WZiJd79gckOm+lLkmjgXhbOsYadEAv89ysw6pPBUPn1ZEWP8nNNtJtMT3g1aLLjwphMiZw65RZHQ338sLpc5VeTJfY0XIvCMMIIXnEoE51y448b9CmfzGLdWkuW2O8thY1guhmHiZ526zDQduCjhWytJCvOiDNczGpqHir5Bi6HEW1/YKHKr0ztppENFFYTzsHVNQIIzOT1LdOtVWTxdPyY4aiMy3ZGv9pfnzsQLGJrDVkTuwo+ImG43rwqZmLaN0ToxuzTXaLy+GTJBT2/nJa7sKXuJF2nXp9uXWOy5DKTBSqPTdbepWov+kEe/0qX7O+s4+3XciqK4Z2F8cF5lcclSxvrmUMEjxeEPOGTomr0x3xSKCU8M4tytm+Y1S1Msjaq1zn4XOj1VJ2ndB/FrLY/MMcWHlla88R28RyVThILtP2BGZXHIst5bj25X5GnaWHW/qBVHoesg/Xk2nsnI3UBYud+IFUegyzvBV2EXbKI2GJtf2CHkLjlZEUvKCRvW+AQ2KermhUgVH4xWVzzmj6cobV6PmNp+wPTKr+UrHgbP+8CRBj9eiCsruucVPmFZNX267rhmuv6fyJ9MmhMldMtI4vt99x/LnYrwtP4eX3ggONsLSJrxaZCF3WFW0lM2G5sXOWXkIXaTZ8EH9PEW6ntD4zq1jxZMpUOeqQ4YLUao1Czb4zMrVmyKLtkVgOnzTOBtj8wovJzZCnB2/S/NbqkgD3S5ey02kak7Q8M2Zoha99sm9uJhbi9KiJCKndbEUqhleQNA5VHk+WUr2pbN4rI4hguhS44NB0TtAArm9mRavsDsMrLmnFEWObe+qPGNjCzePfv1xOh+UZut3D56E5YlDZUmiT84k/lZafWczsI7FyfyE/w3q27+RX5JS27/zETQQ+9liTNE/OK7aYTe06/RJpnjXtLO8626qi9GkV2IrYaK9H1hLe7TSZqC4K/WhnlL5CY7tmuy0uZpqdvqaB45G9V3qsKyCaOgsGNAlH68v7AfUSu8HP++qrGetTvVVvxzl8/Fk/3EasGO+yU71tw01QRmZr9KuxN0QgadlQfRCu5MkU9mC0YIz9Sy+9Wn9lO6Po9r5HpIE5kb/mnDdZCMZ7G+Nu0MbSuSjnZZOb1MCfdkFxA3TnCTp6LbxfauKnDv9Ylg4Y9HY5jadoNLaJy8iOlNZGdJrVoj0kTR5QPJKBrRCsWwjXUXiQWn9NT4b/lNWEtNKSYRjTa3j1wRDpc9JCxTldbJS3ezm64A1lsdtUQmnb0zAWAXuD8O5U59Qaa9BD0FoZmQFYQRzN1N4JcPRqvs5AVIdtG4r/vRjhSPN3rj7AvKQ5mgF6GSCrViwQ9qpFyrbdCv0IqlnCaSSyEcycJ7FwiX+z2el+oPceBrkJSBw/715wL3yOLp+CAU6wu/1ABK2S07gZrA65lLsnH2hI5fE7L9EOPLCrlZP73Vx4xzsA7rTVwUK6kMNaGyCDDoT7t+2RxLicSI2zS09muexadV/RvbSPpa/gEQGQdpIgZkBWw5KgvaXpO+yFAf5fBbZzenSywc9K+uh5mHQm2rHCuL5mE93MWauYwDBKx8GglhbE2RALs5pyUNpeLdILKPVga27ld1lqbbDxwzmjQ3fHvTpYIeExMkeO4WuJ90PQqKJjwB/a2DYJr3um8oybUUMHcss8XBQyq8nuapdCUEZB4U2q9CwlklcZvE1OdQL/F3QHu2kX1JB2CZydOEhJBgqy4Jc1FX4q69zTNArK8dJo+mj3k4XASN4GelEO3+/MGMJGXux3oqgiLXGeLGyK/DjzqFyjoZhuYqPK0A30nNnUoiMILkXYHmxjxAyl7ZbeBN9mYazqUsRrT3XaMxfdCvhTcROa0WW6wO01VdrEj90W+JY6j7l5vkzbD2miCmvzilGQchNYwHFZvlPKj6MPcCSd/h5uil8IJcnhyRZa+WUAqvsCZDTJfvvjiY1z4lhX/Hj28WqDhTZ6EzDfqb3BQC/XmNVetEuHA5lZg53aWufXWiRkKpwZWkOfXP4wn1qdShekcDgfnOdGofTuYY1LP0vnggw8++OCDDz744IMPPvjgg1H8B3SWwVuiUTljAAAAAElFTkSuQmCC)![sadsad.png](data:image/png;base64,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)"],"metadata":{"id":"P5I-hnPxsjCl"}},{"cell_type":"code","source":["k = torch.randn(B,T,head_size)\n","q = torch.randn(B,T,head_size)\n","wei = q @ k.transpose(-2, -1) #* head_size**-0.5"],"metadata":{"id":"kIjaAEI5aEFl","executionInfo":{"status":"ok","timestamp":1699068636796,"user_tz":-360,"elapsed":24,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["k.var(), q.var(), wei.var()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_EM5aY4aIbC","executionInfo":{"status":"ok","timestamp":1699068636796,"user_tz":-360,"elapsed":23,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"b91c185c-dc87-4f9b-c427-e6598fb24984"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(1.0449), tensor(1.0700), tensor(17.4690))"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["k = torch.randn(B,T,head_size)\n","q = torch.randn(B,T,head_size)\n","wei = q @ k.transpose(-2, -1) * head_size**-0.5 # this /sqrt(head_size) is done to normalize wei !!important"],"metadata":{"id":"-TLwlGB6aKuJ","executionInfo":{"status":"ok","timestamp":1699068636797,"user_tz":-360,"elapsed":19,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["k.var(), q.var(), wei.var() # look at the wei.var(); at initialization if wei.var() is too big(not diffuse),\n","                            # the softmax(exp()) will make it converge towards one-hot(1's)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BZxViSC-aLwh","executionInfo":{"status":"ok","timestamp":1699068636797,"user_tz":-360,"elapsed":18,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"9dcc6e0f-da0c-4f73-854b-2a601507b654"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.9006), tensor(1.0037), tensor(0.9957))"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UJ1DzNaeaMuL","executionInfo":{"status":"ok","timestamp":1699070238009,"user_tz":-360,"elapsed":409,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"6375a6dd-6ab7-4181-8910-68f057d026d4"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cj0IwQ-waRQa","executionInfo":{"status":"ok","timestamp":1699070239451,"user_tz":-360,"elapsed":4,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"6c2d3084-7866-406f-f0db-56b673a0e2f1"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["batch_size = 4\n","block_size = 8\n","n_embd = 32\n","head_size = 16\n","vocab_size = len(s2i)\n","class Head(nn.Module):\n","    \"\"\"\" one head of self-attention\"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear(n_embd, head_size, bias=False) # w(16,32) or w(8,32) (head_size, n_emb) ||weights->(out_feature, in_feature)\n","        self.query = nn.Linear(n_embd, head_size, bias=False) # w(16,32) (head_size, n_emb)\n","        self.value = nn.Linear(n_embd, head_size, bias=False) # w(16,32) (head_size, n_emb)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size))) # (T,T)(8,8)\n","        # 'tril' is not a parameter in the pytorch module. To assign it to the module we have to add it using register_buffer\n","    def forward(self, x):\n","        B,T,C = x.shape # 4,8,32\n","        #print('wewew',self.key.weight.shape)\n","        k = self.key(x) # (4,8,32) @ (16,32).T -> B,T,head_size=16 ->(4,8,16) || (4,8,32) @ (8,32).T ->(4,8,8)\n","        print('k',k.shape)\n","        q = self.query(x) # B,T,head_size=16 or 8 ||(4,8,32) @ (8,32).T ->(4,8,8)\n","        print('q',q.shape)\n","        # compute attention scores ('affinities')\n","        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B,T=8,C=8) @ (B,C=8,T=8) --> (B,T,T) # scaled attention\n","        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B,T,T)\n","\n","        wei = F.softmax(wei, dim=-1) # (B,T,T)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) #(B,T,head_size=16)\n","\n","        out = wei @ v # (B,T,head_size=16 or 8)\n","        print(out.shape)\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\"\" multiple heads of self-attention in parallel\"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","\n","    def forward(self, x):\n","        return torch.cat([h(x) for h in self.heads], dim=-1) # concat along channel dim(-1), so 4 heads of size 8 will give C=32\n","\n","class FeedForward(nn.Module):\n","    \"\"\" a simple liner layer followed by a non-linearity\"\"\"\n","\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embd, n_embd),\n","            nn.ReLU(),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Block(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self, n_embd, n_head):\n","        # n_embd: embedding dimension, n_head: the number of head we'd like\n","        super().__init__()\n","        head_size = n_embd//n_head\n","        self.sa = MultiHeadAttention(n_head, head_size) # communication\n","        self.ffwd = FeedForward(n_embd)  # computation\n","\n","    def forward(self, x):\n","        x = self.sa(x)\n","        x = self.ffwd(x)\n","        return x\n","\n","class BigramLanguageModel(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        # each token directly reads off the logits for the next token from a lookup table\n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n","        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n","        #self.sa_head = Head(n_embd)\n","        #self.sa_head = MultiHeadAttention(4, n_embd//4) # 4 heads(communication channels) of 8-dimensional self-attention\n","        #self.ffwd = FeedForward(n_embd)\n","        self.blocks = nn.Sequential(\n","            Block(n_embd, n_head=4),\n","            Block(n_embd, n_head=4),\n","            Block(n_embd, n_head=4),\n","        )\n","        self.lm_head = nn.Linear(n_embd, vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","        # idx and targets are both (B,T) tensor of integers\n","        # each input token/char-int is embedded--> tok_emb\n","        tok_emb = self.token_embedding_table(idx) # (B 4, T 8, C=n_embd 32)\n","\n","        # the position of token in that block_size of token gets embedded ->pos_emb\n","        pos_emb = self.position_embedding_table(torch.arange(T)) # (T, C=n_embd)\n","        #print('pos_emb', pos_emb.shape)\n","        x = tok_emb + pos_emb # (B, T, C=n_embd 32) by broadcasting\n","        #print('x', x.shape)\n","        # x = self.sa_head(x) # apply one/multiple head of self-attention.\n","        #                     #(B,T,C) (4,8,32) # concatanated 4 head of head_size=8 along 'C' dim thus(4,8,8)->(4,8,32)\n","        # print('x after head', x.shape)\n","        # x = self.ffwd(x) # (B,T,C)\n","\n","        x = self.blocks(x) # (B,T,C)\n","\n","        logits = self.lm_head(tok_emb) # (B, T, C=vocab_size)\n","\n","        if targets == None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B,T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # crop idx to the last block_size tokens; because of we added positional encodings, idx can never be > block_size.\n","            idx_cond = idx[:, -block_size:]\n","            logits, loss = self(idx_cond) # get the predictions\n","            logits = logits[:,-1,:] # focus only one the last time step (B, C)\n","            probs = F.softmax(logits, dim=1) # (B,C) apply softmax to get probabilities\n","            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1) sample from the distribution\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1) append sampled index to the running sequence\n","\n","        return idx\n","\n","xb, yb = get_batch('train')\n","print('xb',xb.shape)\n","m = BigramLanguageModel()\n","logits, loss = m(xb, yb) # xb->torch.Size([4, 8]), yb->torch.Size([4, 8])\n","print(logits.shape, loss.item()) # (B*T, C)-> torch.Size([4*8, 65])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3KAzHnBRbHe","executionInfo":{"status":"ok","timestamp":1698955400058,"user_tz":-360,"elapsed":442,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"1be75396-6931-460b-c86d-d1e31fa0e00b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["xb torch.Size([4, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","k torch.Size([4, 8, 8])\n","q torch.Size([4, 8, 8])\n","torch.Size([4, 8, 8])\n","torch.Size([32, 65]) 4.383903980255127\n"]}]},{"cell_type":"code","source":["xb, yb = get_batch('train')\n","xb.shape, vocab_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sX8CIoHXSI0p","executionInfo":{"status":"ok","timestamp":1698949801415,"user_tz":-360,"elapsed":386,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"b1f91c82-1379-4ba1-ccdc-9a7d8cd7d717"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([4, 8]), 65)"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["h = Head(head_size)\n","h.key.weight.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjSUxcc1Uqfn","executionInfo":{"status":"ok","timestamp":1698950283034,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"c6f356c9-9c30-48fe-adc0-8ac007fd8b2f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([16, 32])"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["key = nn.Linear(n_embd, head_size, bias=False)\n","print(key.weight.shape, xb.shape)\n","x = torch.randn((4,8,32))\n","print('x',x.shape)\n","k = key(x)\n","print('k',k.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyUgv4Y8UvQW","executionInfo":{"status":"ok","timestamp":1698950782078,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"35e32919-40c1-4563-80d1-c2a748ecc0c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([16, 32]) torch.Size([4, 8])\n","x torch.Size([4, 8, 32])\n","k torch.Size([4, 8, 16])\n"]}]},{"cell_type":"code","source":["aa = torch.randn((4,8,8))\n","bb = torch.cat([aa for _ in range(4)], dim=-1)\n","aa.shape, bb.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r3RVCPvdfLkx","executionInfo":{"status":"ok","timestamp":1699076166699,"user_tz":-360,"elapsed":438,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"d6d332b0-86e5-47bb-9242-ca79ed60ad8b"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([4, 8, 8]), torch.Size([4, 8, 32]))"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","\n","#--------hyperparameters------------\n","batch_size = 32\n","block_size = 8\n","max_iters = 5000\n","eval_interval =300\n","learning_rate = 1e-3\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 200\n","n_embd = 32\n","head_size = 16\n","#---------------------------------\n","torch.manual_seed(1337)\n","\n","with open('/content/drive/MyDrive/input.txt', 'r', encoding='utf-8') as f:\n","  text = f.read()\n","\n","chars = sorted(list(set(''.join(text))))\n","vocab_size = len(chars)\n","s2i = {ch:i for i, ch in enumerate(chars)}\n","i2s = {i:ch for i, ch in enumerate(chars)}\n","encode = lambda s: [s2i[c] for c in s]\n","decode = lambda l: ''.join([i2s[i] for i in l])\n","\n","data = torch.tensor(encode(text), dtype=torch.long)\n","n = int(0.9*len(data))\n","train_data = data[:n]\n","val_data = data[n:]\n","\n","# data loader\n","def get_batch(split):\n","    data = train_data if split == 'train' else val_data\n","    ix = torch.randint(len(data)-block_size, (batch_size,))\n","    x = torch.stack([data[i:i+block_size] for i in ix])\n","    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","    x, y = x.to(device), y.to(device)\n","    return x, y\n","\n","@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval() # turn off training, turn on eval\n","    for split in [\"train\", \"val\"]:\n","        losses = torch.zeros(eval_iters) # allocate space to log the losses\n","        for k in range(eval_iters):\n","            X, Y = get_batch(split)\n","            logits, loss = model(X,Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train() # turn on training, turn off eval\n","    return out\n","\n","class Head(nn.Module):\n","    \"\"\"\" one head of self-attention\"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear(n_embd, head_size, bias=False) # (32,16) (n_emb, head_size)\n","        self.query = nn.Linear(n_embd, head_size, bias=False) # (32,16) (n_emb, head_size)\n","        self.value = nn.Linear(n_embd, head_size, bias=False) # (32,16) (n_emb, head_size)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size))) # (T,T)(8,8)\n","        # 'tril' is not a parameter in the pytorch module. To assign it to the module we have to add it using register_buffer\n","    def forward(self, x):\n","        B,T,C = x.shape # 4,8,32\n","        k = self.key(x) # (32,16)[4,8,32] -> B,T,head_size=16\n","        q = self.query(x) # B,T,head_size=16\n","        # compute attention scores ('affinities')\n","        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B,T,T) @ (B,C,T) --> (B,T,T) # scaled attention\n","        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # (B,T,T)\n","\n","        wei = F.softmax(wei, dim=-1) # (B,T,T)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) #(B,T,head_size=16)\n","        out = wei @ v # (B,T,head_size=16)\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\"\" multiple heads of self-attention in parallel\"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(n_embd, n_embd) # this is for residual connection, called after the concatanation operation\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1) # residual block of self attention\n","        out = self.proj(out) # the projection back into the residual pathway/highway\n","         # a simple Linear layer to transform output of residual blocks back into the highway\n","        return out\n","\n","class FeedForward(nn.Module):\n","    \"\"\" a simple liner layer followed by a non-linearity\"\"\"\n","\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embd, 4 * n_embd), # 4 * n_embd because attention paper said so and also in the next Linear layer\n","            # done to add extra computation power to the residual block; then scaling it back done when residual block add to the highway\n","            nn.ReLU(),\n","            nn.Linear(4 * n_embd, n_embd), # projection layer going back into the residual highway\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Block(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self, n_embd, n_head):\n","        # n_embd: embedding dimension, n_head: the number of head we'd like\n","        super().__init__()\n","        head_size = n_embd//n_head\n","        self.sa = MultiHeadAttention(n_head, head_size) # communication\n","        self.ffwd = FeedForward(n_embd)  # computation\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x)) # residual connections-> x=gradient highway, self.sa(x)=residual blocks of self attention\n","        x = x + self.ffwd(self.ln2(x))\n","        # layer-norm is added to 'x' \"before\" it is being fed into self-attention and feed-forward\n","        # here normaliztion is done across the C-dim(32), so the B and T act as batch-dimension of normalization\n","        return x\n","\n","class BigramLanguageModel(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","        # each token directly reads off the logits for the next token from a lookup table\n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n","        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n","        ##self.sa_head = Head(n_embd)\n","        #self.sa_head = MultiHeadAttention(4, n_embd//4) # 4 heads(communication channel of 8-dimensional self-attention)\n","        #self.ffwd = FeedForward(n_embd)\n","        self.blocks = nn.Sequential(\n","            Block(n_embd, n_head=4),\n","            Block(n_embd, n_head=4),\n","            Block(n_embd, n_head=4),\n","            nn.LayerNorm(n_embd),\n","        )\n","        self.lm_head = nn.Linear(n_embd, vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","        # idx and targets are both (B,T) tensor of integers\n","        # each input token/char-int is embedded--> tok_emb\n","        tok_emb = self.token_embedding_table(idx) # (B 4, T 8, C=n_embd 32)\n","        # the position of token in that block_size of token gets embedded ->pos_emb\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, C=n_embd)\n","        x = tok_emb + pos_emb # (B, T, C=n_embd) by broadcasting\n","\n","        #x = self.sa_head(x) # apply one head of self-attention. (B,T,C)\n","        #x = self.ffwd(x) # (B,T,C)\n","\n","        x = self.blocks(x) # (B,T,C)\n","\n","        logits = self.lm_head(x) # (B, T, C=vocab_size)\n","\n","        if targets == None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B,T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # crop idx to the last block_size tokens; because of we added positional encodings, idx can never be > block_size.\n","            idx_cond = idx[:, -block_size:]\n","            logits, loss = self(idx_cond) # get the predictions\n","            logits = logits[:,-1,:] # focus only one the last time step (B, C)\n","            probs = F.softmax(logits, dim=1) # (B,C) apply softmax to get probabilities\n","            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1) sample from the distribution\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1) append sampled index to the running sequence\n","\n","        return idx\n","\n","\n","\n","model = BigramLanguageModel()\n","m = model.to(device)\n","\n","# create a pytorch optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","for iter in range(max_iters):\n","\n","    # every once in a while evaluate the loss on train and val sets\n","    if iter % eval_interval == 0:\n","        losses = estimate_loss()\n","        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    # sample a batch of data\n","    xb, yb = get_batch(\"train\")\n","\n","    # evaluate the loss\n","    logits, loss = model(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","\n","# generate from the model\n","context = torch.zeros((1,1), dtype=torch.long, device=device)\n","print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-ESmiqFh3jM","executionInfo":{"status":"ok","timestamp":1699078598065,"user_tz":-360,"elapsed":131174,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"df60c805-06d0-490f-8a23-fcfec28046a9"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["step 0: train loss 4.3103, val loss 4.3097\n","step 300: train loss 2.5220, val loss 2.5316\n","step 600: train loss 2.3644, val loss 2.3668\n","step 900: train loss 2.2732, val loss 2.2837\n","step 1200: train loss 2.1982, val loss 2.2302\n","step 1500: train loss 2.1681, val loss 2.2027\n","step 1800: train loss 2.1355, val loss 2.1766\n","step 2100: train loss 2.1030, val loss 2.1444\n","step 2400: train loss 2.0929, val loss 2.1360\n","step 2700: train loss 2.0808, val loss 2.1282\n","step 3000: train loss 2.0606, val loss 2.1100\n","step 3300: train loss 2.0393, val loss 2.1040\n","step 3600: train loss 2.0314, val loss 2.0995\n","step 3900: train loss 2.0300, val loss 2.0903\n","step 4200: train loss 2.0137, val loss 2.0714\n","step 4500: train loss 2.0096, val loss 2.0822\n","step 4800: train loss 1.9750, val loss 2.0678\n","\n","But, agn cans't thile quen then, and thee.\n","\n","For Wherely our low Set say.\n","\n","FRI CIONCBET:\n","Where of RIORD RINAR DUF:\n","A dePed wart\n","Here, archtre;\n","Ar,\n","Il not; repon;\n","A lis buk pop.\n","\n","ROMENIUS:\n","He? Bong;'t live all it my his him,\n","A that dess, that bettry would.\n","\n","LETER:\n","Oo veer.\n","\n","LUCHAy talk, on brest theier, at as my edo cexea thee stake of reep rane foo wome\n","Hes lase I:\n","My mainds i mils\n","SINING V:\n","The Rightell retwert,\n","To eye.\n","\n","JORY CORDES:\n","The manelbrothers the looks: ploort,\n","Away for mist fom ang bre\n"]}]},{"cell_type":"code","source":["# @title #####Batch-norm to Layer-Norm\n","# commented out the stuff BatchNorm1d needed because it was normalizing across multiple examples in a batch.\n","# If normalization is not done across multiple examples but across each examples themselves, then its layer norm\n","# and LayerNorm does not need to keep track of stuff, since its not coupling several examples togather\n","# and it also doesn't care if it's training or eval mode.\n","# and we can apply this layer norm through out our model\n","class BatchNorm1d:\n","\n","  def __init__(self, dim, eps=1e-5, momentum=0.1):\n","    self.eps = eps\n","    #self.momentum = momentum\n","    #self.training = True\n","    # parameters (trained with backprop)\n","    self.gamma = torch.ones(dim)\n","    self.beta = torch.zeros(dim)\n","    # buffers (trained with a running 'momentum update')\n","    #self.running_mean = torch.zeros(dim)\n","    #self.running_var = torch.ones(dim)\n","\n","  def __call__(self, x):\n","    # calculate the forward pass\n","    #if self.training:\n","      # xmean = x.mean(0, keepdim=True) # batch mean\n","      # xvar  = x.var(0, keepdim=True, unbiased=True) # batch variance\n","    xmean = x.mean(1, keepdim=True) # layer mean\n","    xvar  = x.var(1, keepdim=True, unbiased=True) # layer variance\n","    # else:\n","    #   xmean = self.running_mean\n","    #   xvar  = self.running_var\n","\n","    xhat = (x - xmean)/torch.sqrt(xvar+self.eps) # normalize to unit variance\n","    self.out = self.gamma * xhat + self.beta\n","    # # update the buffers\n","    # if self.training:\n","    #   with torch.no_grad():\n","    #     self.running_mean = (1-self.momentum) * self.running_mean + self.momentum * xmean\n","    #     self.running_var  = (1-self.momentum) * self.running_var + self.momentum * xvar\n","\n","    return self.out\n","\n","  def parameters(self):\n","    return [self.gamma, self.beta]\n","\n","torch.manual_seed(1337)\n","module = BatchNorm1d(100)\n","x = torch.randn(32,100) # batch size 32 of 100-dimensional vectors\n","x = module(x)\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDNfpp6C4wpN","executionInfo":{"status":"ok","timestamp":1699078026580,"user_tz":-360,"elapsed":381,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"5d03e42d-da59-4514-8d38-62843cd66096"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 100])"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["x[:,0].mean(), x[:,0].std() # mean, std of one feature across all batch inputs  (batch-norm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ztrH6pMj5rwk","executionInfo":{"status":"ok","timestamp":1699077383400,"user_tz":-360,"elapsed":381,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"1c9a335f-cb12-4ee7-b524-1e536db9d4cc"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(7.4506e-09), tensor(1.0000))"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features # these rows are not normalized by default (batch-norm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-TUNO3pf52D7","executionInfo":{"status":"ok","timestamp":1699077426771,"user_tz":-360,"elapsed":562,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"9f236ae3-1091-4ccd-a5fc-fb9f9b7f30b1"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.0411), tensor(1.0431))"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["x[:,0].mean(), x[:,0].std() # mean, std of one feature across all batch inputs  (layer-norm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bZifL6S06uVk","executionInfo":{"status":"ok","timestamp":1699078029789,"user_tz":-360,"elapsed":409,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"1cd5fd97-11ff-441b-d534-7a58e67d1a99"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.1469), tensor(0.8803))"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features (layer-norm) # now the normalization is occuring across the rows"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ij7jHywL6uJM","executionInfo":{"status":"ok","timestamp":1699078031063,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"0c95594c-58c3-4dbf-decf-e60375df6683"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(-9.5367e-09), tensor(1.0000))"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["# @title #####dropout\n","'''\n","Dropout is added to help prevent overfitting to data by shutting done some connections randomly\n","Dropout takes your neural net and every forward & backward pass shuts(sets to 0) of some subset of neurons, and trains without them/those connections\n","\n","And since what is being dropped out is changing every forward and backward pass, the NN ends up training an ensemble of sub-networks and at test time all the neurons are fully enabled\n","and all of those sub-networks are merged into a single ensemble.\n","\n","This is basically a regularization method\n","'''\n","print(\"dropout\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ky8JIyyAAg41","executionInfo":{"status":"ok","timestamp":1699079458193,"user_tz":-360,"elapsed":6,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"a1b4efbb-ad5c-4021-c88f-fe8a4e1b9cb2"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["dropout\n"]}]}]}