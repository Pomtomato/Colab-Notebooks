{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOAhHPnog5oYzcoFCQ+qxOT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"3vlEo32F_Y59","executionInfo":{"status":"ok","timestamp":1695019397419,"user_tz":-360,"elapsed":5561,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","from sklearn.model_selection import train_test_split\n","import torch.nn.functional as  F"]},{"cell_type":"code","source":["words = open('/content/names.txt','r').read().splitlines()"],"metadata":{"id":"71Ead5qz_5b8","executionInfo":{"status":"ok","timestamp":1695019410545,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["chars = list(sorted(set(''.join(words))))\n","s2i = {s:i+1 for i ,s in enumerate(chars)}\n","s2i['<S>'] = 0\n","s2i['<E>'] = 27\n","i2s = {i:s for s,i in s2i.items()}"],"metadata":{"id":"2tUIn20YAC27","executionInfo":{"status":"ok","timestamp":1695019416039,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["N = torch.zeros((28,28,28), dtype=torch.int32)\n","\n","for w in words:\n","  chr = ['<S>'] + list(w) + ['<E>']\n","  for ch1,ch2,ch3 in zip(chr,chr[1:], chr[2:]):\n","    ix1 = s2i[ch1]\n","    ix2 = s2i[ch2]\n","    ix3 = s2i[ch3]\n","    N[ix1,ix2,ix3] += 1\n","N"],"metadata":{"id":"rxLaKEUrA3qT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inspect_N(ch1, ch2, ch3):\n","    # Returns how many times a given ch3 appears after a ch1, ch2 sequence.\n","    ix1 = s2i[ch1]\n","    ix2 = s2i[ch2]\n","    ix3 = s2i[ch3]\n","    print(f'At position ({ix1}, {ix2}, {ix3})')\n","    return N[ix1, ix2, ix3].item()\n","\n","inspect_N('a','b','<E>')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WzuaxGX9BoQT","executionInfo":{"status":"ok","timestamp":1695019431507,"user_tz":-360,"elapsed":14,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"fd9d54a8-3303-4c6f-bf0e-193821eba449"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["At position (1, 2, 27)\n"]},{"output_type":"execute_result","data":{"text/plain":["36"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["P = (N+1).float()\n","P /= P.sum(dim=2, keepdim=True)\n","P.shape, P.sum(dim=2, keepdim=True).shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cn4xACy4B8lC","executionInfo":{"status":"ok","timestamp":1695019431508,"user_tz":-360,"elapsed":13,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"af35d47b-9c9f-4ba3-8ca1-52a9e727bc01"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([28, 28, 28]), torch.Size([28, 28, 1]))"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["g = torch.Generator().manual_seed(21437) # keeps the same 'randomness' generated\n","\n","for i in range(10):\n","    ix1, ix2 = 0, 0\n","    out = []\n","    while True:\n","\n","        p = P[ix1, ix2,:] # This can only happen (sampling from '.','.' sequence because we smoothed with (N+1).float()!!!!!)\n","        # Or else, this prob dist would all be 'nan' (i.e None), and it'd give us an error. Our assert above even checks for this! Damn, asserts op!\n","\n","        ix1 = ix2 # Move our characters along\n","        ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n","        out.append(i2s[ix2])\n","\n","        if ix2 == 27:\n","            break\n","    print(''.join(out))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4zpGRyxKDNY1","executionInfo":{"status":"ok","timestamp":1695019431509,"user_tz":-360,"elapsed":10,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"86a196d5-8914-4edd-f6d6-b4c07704e8e6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["pjeem<E>\n","pre<E>\n","q<S>braarryah<E>\n","won<E>\n","gitalandez<E>\n","dea<E>\n","qaxby<E>\n","aana<E>\n","pancyty<E>\n","paroni<E>\n"]}]},{"cell_type":"code","source":["log_likelihood = 0.0\n","n = 0\n","for w in words:\n","    chs =  ['<S>'] + list(w) + ['<E>']\n","    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n","        ix1 = s2i[ch1]\n","        ix2 = s2i[ch2]\n","        ix3 = s2i[ch3]\n","\n","        prob = P[ix1, ix2, ix3] # get probability of ch3 appearing after ch1, ch2\n","        logprob = torch.log(prob)\n","        log_likelihood += logprob # Log likelihood, logprob range is -inf -> 0\n","        n +=1\n","        # print(f\"{ch1}{ch2}: {prob:.4f}, {logprob:.4f}\")\n","\n","print(f'{log_likelihood=}')\n","\n","nll = -log_likelihood # a very nice loss function -- lowest it gets is 0. Higher it is, worse off the predictions are\n","print(f'{nll=}') # summed nll\n","print(f'{nll/n=}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xvpSpnTuE3Kr","executionInfo":{"status":"ok","timestamp":1695019436411,"user_tz":-360,"elapsed":3770,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"dd046fe9-1e6c-4a9f-ad0f-1ebdd09a8b30"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["log_likelihood=tensor(-410786.3750)\n","nll=tensor(410786.3750)\n","nll/n=tensor(2.0946)\n"]}]},{"cell_type":"code","source":["# @title NN\n","\n","# Create training set for trigram\n","def generate_training_set(words):\n","    \"\"\" Returns the xs, ys,\"\"\"\n","    xs, ys = [], [] # trigram labels. given xs, label ys. Ofc, we want these in integers so we convert char -> int below\n","    for w in words:\n","        chs = ['<S>'] + list(w) + ['<E>'] # Adding special token\n","        # print(list(zip(chs, chs[1:], chs[2:]))) # DON'T UNPRINT THIS WITHOUT CAPPING OFF THE WORDS to like words[:3]\n","\n","        for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]): # zip makes 'emma' -> '(e,m),(m,m),(m,a)'.  Ofc we have special tokens too so it different.\n","            ix1 =   s2i[ch1]\n","            ix2 =   s2i[ch2]\n","            ixOut = s2i[ch3]\n","            xs.append((ix1, ix2))\n","            ys.append(ixOut)\n","            #print(xs)\n","\n","    xs = torch.tensor(xs)\n","    ys = torch.tensor(ys)\n","\n","    return xs, ys\n","\n","xs, ys = generate_training_set(words[:1])\n","xs, xs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yx20RhBnGavq","executionInfo":{"status":"ok","timestamp":1695019436412,"user_tz":-360,"elapsed":10,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"16a5e9db-6c69-43bb-fa13-42d3791cee93"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0,  5],\n","         [ 5, 13],\n","         [13, 13],\n","         [13,  1]]),\n"," torch.Size([4, 2]))"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["xenc = F.one_hot(xs, num_classes=28)"],"metadata":{"id":"4GcwGEE3Gv3G","executionInfo":{"status":"ok","timestamp":1695019436414,"user_tz":-360,"elapsed":8,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["xenc_flat = xenc.reshape(4,-1).float() # -1 will infer from the remaining dimensions so xenc(4,2,28)->xenc_flat(4,56) 2*28=56\n","xenc_flat, xenc_flat.shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UT72_GSRPwNp","executionInfo":{"status":"ok","timestamp":1695019436415,"user_tz":-360,"elapsed":9,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"6d595c48-4c4d-4ea5-e524-686be5d77b5c"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0.],\n","         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0.],\n","         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n","          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","          0., 0.]]),\n"," torch.Size([4, 56]))"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# initialise weights, make one forward pass through network (getting logits) and normalise it.\n","g = torch.Generator().manual_seed(2147483647)\n","W = torch.randn((28*2, 28), generator=g, requires_grad=True) # Was (27,1) before for '1' neuron, but if you make it (27,27) it effectively evaluates all 27 neurons on all 5 inputs.\n","\n","logits = xenc_flat @ W\n","# logits.shape\n","counts = logits.exp()\n","probs = counts / counts.sum(1, keepdim=True)\n","print(probs, probs.shape)\n","# Get loss too\n","loss = -probs[torch.arange(4), ys].log().mean()\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BexcOk9RRFXQ","executionInfo":{"status":"ok","timestamp":1695019436968,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"08f0747d-2b27-470f-fc5d-ffe692157c1a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.0926, 0.0035, 0.0023, 0.0119, 0.0635, 0.0294, 0.0024, 0.0183, 0.0109,\n","         0.0345, 0.0060, 0.1306, 0.0118, 0.0072, 0.0157, 0.2064, 0.0586, 0.0018,\n","         0.0160, 0.0042, 0.0326, 0.0118, 0.0033, 0.0027, 0.0078, 0.1925, 0.0137,\n","         0.0081],\n","        [0.0890, 0.0099, 0.0252, 0.0026, 0.0067, 0.0640, 0.0200, 0.0014, 0.0149,\n","         0.0023, 0.0201, 0.0192, 0.0004, 0.2165, 0.0105, 0.0091, 0.0357, 0.0069,\n","         0.0013, 0.0382, 0.0423, 0.0251, 0.0364, 0.0057, 0.2466, 0.0176, 0.0222,\n","         0.0103],\n","        [0.0882, 0.0167, 0.0091, 0.0171, 0.0029, 0.0636, 0.0055, 0.0028, 0.0069,\n","         0.0030, 0.0139, 0.0852, 0.0043, 0.0321, 0.0924, 0.0043, 0.1504, 0.0065,\n","         0.0198, 0.0125, 0.2216, 0.0203, 0.0124, 0.0117, 0.0106, 0.0375, 0.0089,\n","         0.0398],\n","        [0.0365, 0.0358, 0.0052, 0.0102, 0.0083, 0.0379, 0.0215, 0.0075, 0.0037,\n","         0.0114, 0.0111, 0.0638, 0.0571, 0.0065, 0.2060, 0.0154, 0.2059, 0.0234,\n","         0.0470, 0.0038, 0.0016, 0.0133, 0.0127, 0.0147, 0.0084, 0.0151, 0.0190,\n","         0.0971]], grad_fn=<DivBackward0>) torch.Size([4, 28])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(3.2225, grad_fn=<NegBackward0>)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["ys"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtdizVnLtY4V","executionInfo":{"status":"ok","timestamp":1694977558010,"user_tz":-360,"elapsed":428,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"a5df44f3-90de-4cce-b436-43d011c8b62a"},"execution_count":227,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([13, 13,  1, 27])"]},"metadata":{},"execution_count":227}]},{"cell_type":"code","source":["probs[torch.arange(4), ys]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IT9ER4SEtJ5O","executionInfo":{"status":"ok","timestamp":1694977559914,"user_tz":-360,"elapsed":3,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"892ce5f0-1689-48ea-a433-c0c331b60419"},"execution_count":228,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0072, 0.2165, 0.0167, 0.0971], grad_fn=<IndexBackward0>)"]},"metadata":{},"execution_count":228}]},{"cell_type":"code","source":["W.grad = None\n","loss.backward()"],"metadata":{"id":"WooQR4cGTTsx","executionInfo":{"status":"ok","timestamp":1695019442036,"user_tz":-360,"elapsed":8,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["plt.imshow(W.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"id":"X5pQ_t7CTZVZ","executionInfo":{"status":"ok","timestamp":1695019444661,"user_tz":-360,"elapsed":674,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"cad3fcbd-6dd0-4a64-af87-a7c2e1991336"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7c2adbe3f670>"]},"metadata":{},"execution_count":16},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["xs, ys = generate_training_set(words)\n","xs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kslSsbjTo4tm","executionInfo":{"status":"ok","timestamp":1695019446431,"user_tz":-360,"elapsed":537,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"0d4ba469-42fd-47a6-9945-a3ceabcf406f"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([196113, 2])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["def train_trigram(xs, ys, epochs, lr, W=None) -> torch.tensor:\n","\n","  if W == None:\n","    g = torch.Generator().manual_seed(2147483647)\n","    W = torch.randn((28*2, 28), generator=g, requires_grad=True)\n","\n","  if xs.shape[1] != 56: # hard-coded\n","    xenc = F.one_hot(xs, num_classes=28)\n","\n","    xenc_flat = xenc.reshape(len(xenc), -1).float()\n","  else:\n","    xenc_flat=xs\n","\n","  num_examples = xs.shape[0]\n","  print(f\"Number of examples: {num_examples}\")\n","  for i in range(epochs):\n","    #xenc = F.one_hot(xs, num_classes=28)\n","\n","    #xenc_flat = xenc.reshape(len(xenc), -1).float()\n","    #xenc_flat = xenc.reshape(xenc.shape[0], -1).float()\n","\n","    # xenc_flat @ W -> (196113, 56) @ (56,28)\n","\n","    #xenc_flat=xs\n","    # forward pass\n","    logits = xenc_flat @ W\n","    counts = logits.exp()\n","    probs = counts / counts.sum(dim=1, keepdim=True)\n","    loss = -probs[torch.arange(num_examples), ys].log().mean()\n","\n","    print(f\"Epoch: {i} || Loss: {loss}\")\n","    # backward pass\n","    W.grad = None\n","    loss.backward()\n","\n","    # Update weights\n","    W.data += -lr * W.grad\n","\n","  return W, loss.item()"],"metadata":{"id":"IceZF8HqTb9R","executionInfo":{"status":"ok","timestamp":1695019446433,"user_tz":-360,"elapsed":6,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["model_weights = None"],"metadata":{"id":"SjdTHzy6q7Dm","executionInfo":{"status":"ok","timestamp":1695019448162,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["model_weights, loss1 = train_trigram(xs, ys, 100, 50, W=model_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1jC8O6Bo6r2","executionInfo":{"status":"ok","timestamp":1695019462869,"user_tz":-360,"elapsed":13222,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"80e7facc-caf5-4ad7-a40f-55a7e068f11c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of examples: 196113\n","Epoch: 0 || Loss: 3.98872971534729\n","Epoch: 1 || Loss: 3.2773752212524414\n","Epoch: 2 || Loss: 3.016171455383301\n","Epoch: 3 || Loss: 2.8558714389801025\n","Epoch: 4 || Loss: 2.7481861114501953\n","Epoch: 5 || Loss: 2.672719717025757\n","Epoch: 6 || Loss: 2.6172494888305664\n","Epoch: 7 || Loss: 2.5745604038238525\n","Epoch: 8 || Loss: 2.5404233932495117\n","Epoch: 9 || Loss: 2.5124261379241943\n","Epoch: 10 || Loss: 2.4890310764312744\n","Epoch: 11 || Loss: 2.4692015647888184\n","Epoch: 12 || Loss: 2.452179431915283\n","Epoch: 13 || Loss: 2.4374027252197266\n","Epoch: 14 || Loss: 2.4244420528411865\n","Epoch: 15 || Loss: 2.4129743576049805\n","Epoch: 16 || Loss: 2.40274977684021\n","Epoch: 17 || Loss: 2.3935773372650146\n","Epoch: 18 || Loss: 2.3853046894073486\n","Epoch: 19 || Loss: 2.3778107166290283\n","Epoch: 20 || Loss: 2.3709945678710938\n","Epoch: 21 || Loss: 2.3647735118865967\n","Epoch: 22 || Loss: 2.3590757846832275\n","Epoch: 23 || Loss: 2.353841543197632\n","Epoch: 24 || Loss: 2.3490183353424072\n","Epoch: 25 || Loss: 2.3445613384246826\n","Epoch: 26 || Loss: 2.3404316902160645\n","Epoch: 27 || Loss: 2.3365938663482666\n","Epoch: 28 || Loss: 2.333019733428955\n","Epoch: 29 || Loss: 2.329681873321533\n","Epoch: 30 || Loss: 2.3265581130981445\n","Epoch: 31 || Loss: 2.3236289024353027\n","Epoch: 32 || Loss: 2.320875883102417\n","Epoch: 33 || Loss: 2.3182849884033203\n","Epoch: 34 || Loss: 2.3158411979675293\n","Epoch: 35 || Loss: 2.3135335445404053\n","Epoch: 36 || Loss: 2.3113510608673096\n","Epoch: 37 || Loss: 2.309284210205078\n","Epoch: 38 || Loss: 2.3073246479034424\n","Epoch: 39 || Loss: 2.305464267730713\n","Epoch: 40 || Loss: 2.303696632385254\n","Epoch: 41 || Loss: 2.3020145893096924\n","Epoch: 42 || Loss: 2.3004136085510254\n","Epoch: 43 || Loss: 2.298887014389038\n","Epoch: 44 || Loss: 2.2974307537078857\n","Epoch: 45 || Loss: 2.2960405349731445\n","Epoch: 46 || Loss: 2.2947113513946533\n","Epoch: 47 || Loss: 2.293440580368042\n","Epoch: 48 || Loss: 2.2922236919403076\n","Epoch: 49 || Loss: 2.291058301925659\n","Epoch: 50 || Loss: 2.289940595626831\n","Epoch: 51 || Loss: 2.2888684272766113\n","Epoch: 52 || Loss: 2.2878384590148926\n","Epoch: 53 || Loss: 2.286848783493042\n","Epoch: 54 || Loss: 2.2858972549438477\n","Epoch: 55 || Loss: 2.2849812507629395\n","Epoch: 56 || Loss: 2.2840993404388428\n","Epoch: 57 || Loss: 2.2832489013671875\n","Epoch: 58 || Loss: 2.2824292182922363\n","Epoch: 59 || Loss: 2.2816383838653564\n","Epoch: 60 || Loss: 2.280874490737915\n","Epoch: 61 || Loss: 2.2801363468170166\n","Epoch: 62 || Loss: 2.2794225215911865\n","Epoch: 63 || Loss: 2.2787320613861084\n","Epoch: 64 || Loss: 2.2780637741088867\n","Epoch: 65 || Loss: 2.277416229248047\n","Epoch: 66 || Loss: 2.2767889499664307\n","Epoch: 67 || Loss: 2.2761807441711426\n","Epoch: 68 || Loss: 2.275590181350708\n","Epoch: 69 || Loss: 2.275017261505127\n","Epoch: 70 || Loss: 2.274461030960083\n","Epoch: 71 || Loss: 2.2739202976226807\n","Epoch: 72 || Loss: 2.2733943462371826\n","Epoch: 73 || Loss: 2.272883415222168\n","Epoch: 74 || Loss: 2.272386074066162\n","Epoch: 75 || Loss: 2.271901845932007\n","Epoch: 76 || Loss: 2.271430492401123\n","Epoch: 77 || Loss: 2.2709708213806152\n","Epoch: 78 || Loss: 2.2705233097076416\n","Epoch: 79 || Loss: 2.2700865268707275\n","Epoch: 80 || Loss: 2.2696609497070312\n","Epoch: 81 || Loss: 2.2692453861236572\n","Epoch: 82 || Loss: 2.2688395977020264\n","Epoch: 83 || Loss: 2.2684438228607178\n","Epoch: 84 || Loss: 2.268057107925415\n","Epoch: 85 || Loss: 2.26767897605896\n","Epoch: 86 || Loss: 2.2673099040985107\n","Epoch: 87 || Loss: 2.266948699951172\n","Epoch: 88 || Loss: 2.2665953636169434\n","Epoch: 89 || Loss: 2.266249895095825\n","Epoch: 90 || Loss: 2.2659120559692383\n","Epoch: 91 || Loss: 2.265580892562866\n","Epoch: 92 || Loss: 2.2652571201324463\n","Epoch: 93 || Loss: 2.264940023422241\n","Epoch: 94 || Loss: 2.2646288871765137\n","Epoch: 95 || Loss: 2.264324903488159\n","Epoch: 96 || Loss: 2.264026165008545\n","Epoch: 97 || Loss: 2.2637341022491455\n","Epoch: 98 || Loss: 2.2634472846984863\n","Epoch: 99 || Loss: 2.2631661891937256\n"]}]},{"cell_type":"code","source":["loss1, model_weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P6KtgffbqFw3","executionInfo":{"status":"ok","timestamp":1695019462869,"user_tz":-360,"elapsed":18,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"729e54f4-2698-476c-9b32-b9831946b8c1"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2.2631661891937256,\n"," tensor([[-1.2466,  2.4377,  0.3382,  ...,  1.1777,  0.8345, -2.8816],\n","         [-2.1990,  0.2891, -0.2941,  ...,  0.1136, -0.2438,  1.2529],\n","         [-0.0710,  1.2343, -0.5666,  ...,  0.8655, -0.4992,  0.4010],\n","         ...,\n","         [-1.7487,  1.9788, -0.5849,  ..., -1.5469, -0.1231,  1.5139],\n","         [-1.0931,  2.2689, -0.0277,  ...,  1.2078, -0.0431,  0.3370],\n","         [-0.0811,  0.4353, -0.0897,  ...,  1.5992,  1.1401,  0.9196]],\n","        requires_grad=True))"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["#xenc = F.one_hot(xs, num_classes=28).float()\n","trial = torch.tensor([0,3])\n","xenc = F.one_hot(trial, num_classes=28).float()\n","xenc_flat = xenc.reshape((1, -1))\n","trial.shape, xenc.shape, len(xenc), xenc_flat.shape, model_weights.shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-z4RSKdnt_3A","executionInfo":{"status":"ok","timestamp":1695019462870,"user_tz":-360,"elapsed":13,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"ac8ec0ce-199b-46c7-f944-502530f7db6e"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([2]),\n"," torch.Size([2, 28]),\n"," 2,\n"," torch.Size([1, 56]),\n"," torch.Size([56, 28]))"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["def generate_random_names(num_names: int, weights) -> None:\n","  g = torch.Generator().manual_seed(2147483647)\n","\n","  for i in range(20):\n","    name = []\n","    ix1 = 0\n","    ix2 = 0\n","    while True:\n","      xenc = F.one_hot(torch.tensor([ix1,ix2]), num_classes=28).float()\n","      # here we are taking a random sample as input, to see how well the trained weights can model random inputs\n","      # torch.tensor([ix1,ix2]) corresponds to feeding just 1 example data\n","      # so xenc_flat-> (1, 56) -> (one example, flat_ch1&ch2)\n","      xenc_flat = xenc.reshape((1, -1))\n","\n","      logits = xenc_flat @ weights\n","      counts = logits.exp()\n","      probs = counts / counts.sum(dim=1,keepdim=True)\n","\n","\n","      ix1 = ix2\n","      ix2 = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n","      name.append(i2s[ix2])\n","      if ix2 == 27:\n","                break\n","\n","    print(''.join(name))\n","  print(f\"probs: {probs}, shape: {probs.shape}\")"],"metadata":{"id":"RelC4MmnpMrl","executionInfo":{"status":"ok","timestamp":1695019462871,"user_tz":-360,"elapsed":10,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["generate_random_names(5, model_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jW-M3fa30rht","executionInfo":{"status":"ok","timestamp":1695019462871,"user_tz":-360,"elapsed":10,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"9d55d31a-e3db-4bdf-a37e-d4bd8ac4ea90"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["aunide<E>\n","ia<E>\n","asa<E>\n","aush<E>\n","ay<E>\n","ainn<E>\n","guith<E>\n","tole<E>\n","amare<E>\n","zusann<E>\n","auvin<E>\n","adviassib<E>\n","ain<E>\n","wi<E>\n","ca<E>\n","seisie<E>\n","yla<E>\n","telin<E>\n","aumer<E>\n","fontumer<E>\n","probs: tensor([[0.0012, 0.1266, 0.0035, 0.0087, 0.0148, 0.0773, 0.0020, 0.0214, 0.0116,\n","         0.1785, 0.0022, 0.0072, 0.0510, 0.0225, 0.0125, 0.0508, 0.0028, 0.0016,\n","         0.0383, 0.0245, 0.0288, 0.0099, 0.0059, 0.0018, 0.0017, 0.0503, 0.0052,\n","         0.2373]], grad_fn=<DivBackward0>), shape: torch.Size([1, 28])\n"]}]},{"cell_type":"markdown","source":["## EXERCISE 2"],"metadata":{"id":"nE_cWJJz4Jxd"}},{"cell_type":"code","source":["from torch.utils.data import random_split"],"metadata":{"id":"jb8I7utc4INu","executionInfo":{"status":"ok","timestamp":1695019467641,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["train_subset, test_subset, valid_subset = random_split(range(100), [0.8, 0.1, 0.1])"],"metadata":{"id":"L3MqN2AOGowC","executionInfo":{"status":"ok","timestamp":1694971428110,"user_tz":-360,"elapsed":551,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":169,"outputs":[]},{"cell_type":"code","source":["len(words),len(train_subset),len(test_subset),len(valid_subset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1YmJ5P-RH1nr","executionInfo":{"status":"ok","timestamp":1694971428832,"user_tz":-360,"elapsed":4,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"76d6ba7e-6464-4e6e-c271-a1dbbda7a9ac"},"execution_count":170,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32033, 80, 10, 10)"]},"metadata":{},"execution_count":170}]},{"cell_type":"code","source":["xs, ys = generate_training_set(words)\n","xenc = F.one_hot(xs, num_classes=28).float()\n","xenc_flat = xenc.reshape((xenc.shape[0], -1))\n","xs.shape, xenc.shape, xenc_flat.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2aWUiXFMEHy","executionInfo":{"status":"ok","timestamp":1695019470894,"user_tz":-360,"elapsed":630,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"7a73ea5b-7e91-4d36-fce0-d4e4df731290"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([196113, 2]),\n"," torch.Size([196113, 2, 28]),\n"," torch.Size([196113, 56]))"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["ys.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUkl1o-nNzlB","executionInfo":{"status":"ok","timestamp":1694972209463,"user_tz":-360,"elapsed":422,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"f0fd55a0-9785-4d87-b685-40fcfc5fb406"},"execution_count":195,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([196113])"]},"metadata":{},"execution_count":195}]},{"cell_type":"code","source":["total_enc_data = xenc_flat.shape[0]\n","print(\"Range of encoded x (i.e number of examples):\", range(total_enc_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I56KPH7bNF8i","executionInfo":{"status":"ok","timestamp":1695019472621,"user_tz":-360,"elapsed":4,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"44371246-e31c-4c05-fe8d-f16394900ba0"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Range of encoded x (i.e number of examples): range(0, 196113)\n"]}]},{"cell_type":"code","source":["train_subset, test_subset, valid_subset = random_split(range(total_enc_data), [0.8, 0.1, 0.1])"],"metadata":{"id":"UGDweH3YMud6","executionInfo":{"status":"ok","timestamp":1695019474256,"user_tz":-360,"elapsed":4,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["train_idx = torch.tensor(train_subset)\n","test_idx = torch.tensor(test_subset)\n","val_idx = torch.tensor(valid_subset)"],"metadata":{"id":"KceuNfWwJB3L","executionInfo":{"status":"ok","timestamp":1695019475062,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["train_idx.shape, test_idx.shape, val_idx.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnlJPlnPJYEK","executionInfo":{"status":"ok","timestamp":1695019475599,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"e0690f74-bdb2-4f08-d7a4-87d139544a15"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([156891]), torch.Size([19611]), torch.Size([19611]))"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["x_train, y_train = xenc_flat[train_idx], ys[train_idx]\n","x_test, y_test = xenc_flat[test_idx], ys[test_idx]\n","x_val, y_val = xenc_flat[val_idx], ys[val_idx]"],"metadata":{"id":"7erCzpijL1mE","executionInfo":{"status":"ok","timestamp":1695019476754,"user_tz":-360,"elapsed":4,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["x_train.shape,y_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G9mlTtLOK1Bk","executionInfo":{"status":"ok","timestamp":1694977666071,"user_tz":-360,"elapsed":723,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"3c08f99a-cc17-43a8-dc07-823eb04a4d0b"},"execution_count":245,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([156891, 56]), torch.Size([156891]))"]},"metadata":{},"execution_count":245}]},{"cell_type":"code","source":["model2_weights, loss2 = train_trigram(x_train, y_train, 100, 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7X2EIrm5K32Y","executionInfo":{"status":"ok","timestamp":1695019489725,"user_tz":-360,"elapsed":10664,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"8d999ab9-86d8-4368-d483-f106244198ad"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of examples: 156891\n","Epoch: 0 || Loss: 3.9879350662231445\n","Epoch: 1 || Loss: 3.2792294025421143\n","Epoch: 2 || Loss: 3.0186843872070312\n","Epoch: 3 || Loss: 2.8586647510528564\n","Epoch: 4 || Loss: 2.751077890396118\n","Epoch: 5 || Loss: 2.6755943298339844\n","Epoch: 6 || Loss: 2.6200814247131348\n","Epoch: 7 || Loss: 2.57735538482666\n","Epoch: 8 || Loss: 2.5431878566741943\n","Epoch: 9 || Loss: 2.5151560306549072\n","Epoch: 10 || Loss: 2.4917211532592773\n","Epoch: 11 || Loss: 2.4718470573425293\n","Epoch: 12 || Loss: 2.4547784328460693\n","Epoch: 13 || Loss: 2.4399564266204834\n","Epoch: 14 || Loss: 2.426954507827759\n","Epoch: 15 || Loss: 2.4154489040374756\n","Epoch: 16 || Loss: 2.405191421508789\n","Epoch: 17 || Loss: 2.3959903717041016\n","Epoch: 18 || Loss: 2.3876941204071045\n","Epoch: 19 || Loss: 2.3801801204681396\n","Epoch: 20 || Loss: 2.373347282409668\n","Epoch: 21 || Loss: 2.367111921310425\n","Epoch: 22 || Loss: 2.3614022731781006\n","Epoch: 23 || Loss: 2.356156826019287\n","Epoch: 24 || Loss: 2.3513238430023193\n","Epoch: 25 || Loss: 2.3468568325042725\n","Epoch: 26 || Loss: 2.342716932296753\n","Epoch: 27 || Loss: 2.338869094848633\n","Epoch: 28 || Loss: 2.3352835178375244\n","Epoch: 29 || Loss: 2.3319339752197266\n","Epoch: 30 || Loss: 2.3287980556488037\n","Epoch: 31 || Loss: 2.3258554935455322\n","Epoch: 32 || Loss: 2.3230888843536377\n","Epoch: 33 || Loss: 2.320483446121216\n","Epoch: 34 || Loss: 2.3180253505706787\n","Epoch: 35 || Loss: 2.315702438354492\n","Epoch: 36 || Loss: 2.313504695892334\n","Epoch: 37 || Loss: 2.311422348022461\n","Epoch: 38 || Loss: 2.3094468116760254\n","Epoch: 39 || Loss: 2.3075709342956543\n","Epoch: 40 || Loss: 2.3057870864868164\n","Epoch: 41 || Loss: 2.3040897846221924\n","Epoch: 42 || Loss: 2.3024723529815674\n","Epoch: 43 || Loss: 2.3009307384490967\n","Epoch: 44 || Loss: 2.2994587421417236\n","Epoch: 45 || Loss: 2.2980527877807617\n","Epoch: 46 || Loss: 2.2967092990875244\n","Epoch: 47 || Loss: 2.2954227924346924\n","Epoch: 48 || Loss: 2.294191598892212\n","Epoch: 49 || Loss: 2.2930116653442383\n","Epoch: 50 || Loss: 2.291879892349243\n","Epoch: 51 || Loss: 2.2907931804656982\n","Epoch: 52 || Loss: 2.289750099182129\n","Epoch: 53 || Loss: 2.2887470722198486\n","Epoch: 54 || Loss: 2.2877821922302246\n","Epoch: 55 || Loss: 2.286853551864624\n","Epoch: 56 || Loss: 2.285959005355835\n","Epoch: 57 || Loss: 2.285097122192383\n","Epoch: 58 || Loss: 2.2842650413513184\n","Epoch: 59 || Loss: 2.2834622859954834\n","Epoch: 60 || Loss: 2.2826874256134033\n","Epoch: 61 || Loss: 2.281937837600708\n","Epoch: 62 || Loss: 2.2812137603759766\n","Epoch: 63 || Loss: 2.280512571334839\n","Epoch: 64 || Loss: 2.279834032058716\n","Epoch: 65 || Loss: 2.2791764736175537\n","Epoch: 66 || Loss: 2.2785394191741943\n","Epoch: 67 || Loss: 2.277921676635742\n","Epoch: 68 || Loss: 2.277322292327881\n","Epoch: 69 || Loss: 2.276740550994873\n","Epoch: 70 || Loss: 2.2761754989624023\n","Epoch: 71 || Loss: 2.2756261825561523\n","Epoch: 72 || Loss: 2.275092124938965\n","Epoch: 73 || Loss: 2.2745730876922607\n","Epoch: 74 || Loss: 2.2740676403045654\n","Epoch: 75 || Loss: 2.273576021194458\n","Epoch: 76 || Loss: 2.273097038269043\n","Epoch: 77 || Loss: 2.272630453109741\n","Epoch: 78 || Loss: 2.2721757888793945\n","Epoch: 79 || Loss: 2.2717323303222656\n","Epoch: 80 || Loss: 2.2712998390197754\n","Epoch: 81 || Loss: 2.2708778381347656\n","Epoch: 82 || Loss: 2.270465850830078\n","Epoch: 83 || Loss: 2.270064115524292\n","Epoch: 84 || Loss: 2.2696712017059326\n","Epoch: 85 || Loss: 2.269287347793579\n","Epoch: 86 || Loss: 2.2689123153686523\n","Epoch: 87 || Loss: 2.268545627593994\n","Epoch: 88 || Loss: 2.2681870460510254\n","Epoch: 89 || Loss: 2.267836332321167\n","Epoch: 90 || Loss: 2.2674927711486816\n","Epoch: 91 || Loss: 2.2671570777893066\n","Epoch: 92 || Loss: 2.2668282985687256\n","Epoch: 93 || Loss: 2.2665061950683594\n","Epoch: 94 || Loss: 2.266191005706787\n","Epoch: 95 || Loss: 2.2658820152282715\n","Epoch: 96 || Loss: 2.2655792236328125\n","Epoch: 97 || Loss: 2.265282392501831\n","Epoch: 98 || Loss: 2.264991521835327\n","Epoch: 99 || Loss: 2.2647063732147217\n"]}]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5fIaoG7Pg9z","executionInfo":{"status":"ok","timestamp":1695019489726,"user_tz":-360,"elapsed":13,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"4d2b42f8-b63f-4ccc-be8c-309d126f1f43"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([156891, 56])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["def evaluate_model(xs, ys, W):\n","  logits = xs @ W\n","  counts = logits.exp()\n","  probs = counts / counts.sum(dim=1,keepdim=True)\n","  loss = -probs[torch.arange(x_val.shape[0]), ys].log().mean()\n","  return loss"],"metadata":{"id":"YSgkRT0sPCH6","executionInfo":{"status":"ok","timestamp":1695019489727,"user_tz":-360,"elapsed":9,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["val_loss = evaluate_model(x_val,y_val, model2_weights)\n","test_loss = evaluate_model(x_test,y_test, model2_weights)\n","print(f\"Val Loss: {val_loss} || Test Loss: {test_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fwUiw8DqQyTQ","executionInfo":{"status":"ok","timestamp":1695019493949,"user_tz":-360,"elapsed":4,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"6b682815-bdac-4849-bc17-2f8f8f76a058"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Val Loss: 2.2463879585266113 || Test Loss: 2.2682180404663086\n"]}]},{"cell_type":"code","source":["generate_random_names(5, model2_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mxF-UD9JQrKh","executionInfo":{"status":"ok","timestamp":1695019497808,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"1a0b4c03-2586-4f6f-fd0a-391cd81e3923"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["aunide<E>\n","ia<E>\n","asa<E>\n","aush<E>\n","ay<E>\n","ainn<E>\n","guith<E>\n","tole<E>\n","amare<E>\n","zusann<E>\n","aur<E>\n","ailen<E>\n","assib<E>\n","ain<E>\n","wi<E>\n","ca<E>\n","seisie<E>\n","yla<E>\n","telin<E>\n","aumer<E>\n","probs: tensor([[0.0012, 0.1253, 0.0033, 0.0095, 0.0166, 0.0770, 0.0020, 0.0221, 0.0112,\n","         0.1746, 0.0021, 0.0067, 0.0528, 0.0251, 0.0131, 0.0510, 0.0028, 0.0014,\n","         0.0383, 0.0251, 0.0287, 0.0095, 0.0064, 0.0018, 0.0016, 0.0479, 0.0051,\n","         0.2378]], grad_fn=<DivBackward0>), shape: torch.Size([1, 28])\n"]}]},{"cell_type":"code","source":["def train_trigram_with_reg(xs, ys, epochs, lr:float, reg:float, W=None) -> torch.tensor:\n","\n","  if W == None:\n","    g = torch.Generator().manual_seed(2147483647)\n","    W = torch.randn((28*2, 28), generator=g, requires_grad=True)\n","\n","  if xs.shape[1] != 56: # hard-coded\n","    xenc = F.one_hot(xs, num_classes=28)\n","\n","    xenc_flat = xenc.reshape(len(xenc), -1).float()\n","  else:\n","    xenc_flat=xs\n","\n","  num_examples = xs.shape[0]\n","  loss_list = []\n","  print(f\"Number of examples: {num_examples}\")\n","  for i in range(epochs):\n","    #xenc = F.one_hot(xs, num_classes=28)\n","\n","    #xenc_flat = xenc.reshape(len(xenc), -1).float()\n","    #xenc_flat = xenc.reshape(xenc.shape[0], -1).float()\n","\n","    # xenc_flat @ W -> (196113, 56) @ (56,28)\n","\n","    #xenc_flat=xs\n","    # forward pass\n","    logits = xenc_flat @ W\n","    counts = logits.exp()\n","    probs = counts / counts.sum(dim=1, keepdim=True)\n","    loss = -probs[torch.arange(num_examples), ys].log().mean() + reg * (W**2).mean()\n","\n","    loss_list.append(loss.item())\n","    print(f\"Epoch: {i} || Loss: {loss}\")\n","\n","    # backward pass\n","    W.grad = None\n","    loss.backward()\n","\n","    # Update weights\n","    W.data += -lr * W.grad\n","\n","  plot_loss(range(1,epochs+1) ,loss_list , reg, lr)\n","\n","  return W, loss.item()"],"metadata":{"id":"uVB5nkeWnh6q","executionInfo":{"status":"ok","timestamp":1695019500936,"user_tz":-360,"elapsed":518,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["model_reg_W, loss3 = train_trigram_with_reg(xenc_flat,ys, 100, 50, 0.1)"],"metadata":{"id":"lOkb8e1Uqeo0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reg = [0.01, 0.05, 0.1, 0.2, 0.5]\n","for i in range(len(reg)):\n","  model_reg_W, loss3 = train_trigram_with_reg(xenc_flat,ys, 50, 50, reg[i])\n","  print(loss3)"],"metadata":{"id":"YjYOOC7QzQh0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss1, loss2, loss3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jE9SZTJorFll","executionInfo":{"status":"ok","timestamp":1694980685623,"user_tz":-360,"elapsed":428,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"dc795354-01c0-49bd-e644-321c18e02d4f"},"execution_count":282,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2.2631661891937256, 2.260226011276245, 2.329425573348999)"]},"metadata":{},"execution_count":282}]},{"cell_type":"code","source":["def plot_loss(epoch, loss, reg=None, lr=None):\n","  plt.figure(figsize=(12,8))\n","  plt.plot(epoch, loss)\n","  plt.xlabel('epochs')\n","  plt.ylabel('loss')\n","  plt.title(f\"Loss vs Epoch for reg: {reg} and lr: {lr}\")"],"metadata":{"id":"KIReVV6-rTiM","executionInfo":{"status":"ok","timestamp":1695019516307,"user_tz":-360,"elapsed":3,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["## EXERCISE 4\n","we saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?<br>\n","\n","\n","Neat Indexing trick:\n","```\n","g = torch.Generator().manual_seed(2147483647)\n","ww = torch.randn((28*2,28), generator=g,requires_grad=True)\n","ww1 = W[:28]\n","ww2 = W[28:]\n","wq1 = ww1[xs[:,0]] + ww2[xs[:,1]]\n","ww1.shape, ww2.shape\n","\n","xs[:,0][:5]\n","ww1[xs[:,0][:5]] , ww2[xs[:,0][:5]]\n","```\n","ww1[xs[:,0]]-> (196113, 28) ww2[xs[:,1]]->(196113, 28)\n","ww1 are weights of the 1st char of all the examples\n","ww2 are weights of the 2nd char of all the examples\n","\n","now ww1[xs[:,0]] + ww2[xs[:,1]] will mean all characters weights are added in accordance to their context\n","\n","e.g.    [[ 0,  5], <br>\n","        [ 5, 13],<br>\n","        [13, 13],<br>\n","        ...,<br>\n","        [26, 25],<br>\n","        [25, 26],<br>\n","        [26, 24]] <br><br>\n","[0,5]-> '0' 1st char, '5' 2nd char and we do ww1(for'0') + ww2(for'5')\n"],"metadata":{"id":"Wk7REmgy1HTN"}},{"cell_type":"code","source":["xs, ys = generate_training_set(words)"],"metadata":{"id":"Qt7RF4Dl1KWT","executionInfo":{"status":"ok","timestamp":1695023169593,"user_tz":-360,"elapsed":889,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["def train_trigram_reg_idx(xs, ys, epochs:int, lr=50, reg=0, W=None):\n","\n","  if W == None:\n","    g = torch.Generator().manual_seed(2147483647)\n","    W = torch.randn((28*2,28), generator=g,requires_grad=True)\n","\n","  num_ex =  xs.shape[0]\n","  print(f\"Num of Example: {num_ex}\")\n","\n","  for i in range(epochs):\n","    # forward\n","    ww1 = W[:28] # (28,28)\n","    ww2 = W[28:]  # (28,28)\n","    logits = ww1[xs[:,0]] + ww2[xs[:,1]]  # [196113, 28] + [196113, 28]\n","    counts = logits.exp()\n","    probs = counts/counts.sum(dim=1, keepdim=True)\n","    loss = -probs[torch.arange(num_ex), ys].log().mean() + reg * (W**2).mean()\n","    print(f'Epoch {i}. Loss: {loss.item():.4f}')\n","\n","    # backward\n","    W.grad = None\n","    loss.backward()\n","\n","    # update\n","    W.data += -lr * W.grad\n","\n","  return W\n","\n"],"metadata":{"id":"0YkayTgGC7Bi","executionInfo":{"status":"ok","timestamp":1695023308263,"user_tz":-360,"elapsed":3,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["x_train, y_train = xs[train_idx], ys[train_idx]\n","x_val, y_val = xs[val_idx], ys[val_idx]\n","x_test, y_test = xs[test_idx], ys[test_idx]"],"metadata":{"id":"J9awbiajQmlV","executionInfo":{"status":"ok","timestamp":1695023266474,"user_tz":-360,"elapsed":4,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["model = train_trigram_reg_idx(x_train, y_train, 100, 50)"],"metadata":{"id":"yav8eaaUOldr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_loss_idx(W, x, y):\n","  W1 = W[:28]\n","  W2 = W[28:]\n","  logits = W1[x[:,0]] + W2[x[:,1]]\n","  counts = logits.exp()\n","  prob = counts/counts.sum(1, keepdims=True)\n","  return -prob[torch.arange(x.shape[0]), y].log().mean()"],"metadata":{"id":"YpQ3RGiXNw2X","executionInfo":{"status":"ok","timestamp":1695024591681,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}}},"execution_count":117,"outputs":[]},{"cell_type":"code","source":["evaluate_loss_idx(model, x_val, y_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4LJSFS2QW-z","executionInfo":{"status":"ok","timestamp":1695024598940,"user_tz":-360,"elapsed":564,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"9474651a-b79d-4ac4-db96-54b382267a16"},"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.2464, grad_fn=<NegBackward0>)"]},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":["evaluate_loss_idx(model, x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Suzi-qGfVuZW","executionInfo":{"status":"ok","timestamp":1695024616641,"user_tz":-360,"elapsed":5,"user":{"displayName":"Abrar Raiyan","userId":"03612250197745345037"}},"outputId":"7dee20b5-f57d-4fa0-e7c4-851ae32ca6c4"},"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.2682, grad_fn=<NegBackward0>)"]},"metadata":{},"execution_count":119}]},{"cell_type":"markdown","source":["\n","##E05:\n","\n","look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?\n"],"metadata":{"id":"O-1WXz6XV3uG"}},{"cell_type":"code","source":[],"metadata":{"id":"G13u7SMyV6hq"},"execution_count":null,"outputs":[]}]}